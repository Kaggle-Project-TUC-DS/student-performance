{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, StratifiedKFold\n",
    "\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.classification.dictionary_based import MUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow v2.11.1\n",
      "Working Directory:  /Users/nzuchna/Desktop/Drive/2. Areas/University/Master-TUC/M2/4_Forschungsmodul/student-performance\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow v\" + tf.__version__)\n",
    "# get working directory and remove last folder\n",
    "wd = os.path.dirname(os.getcwd())\n",
    "os.chdir(wd)\n",
    "print(\"Working Directory: \", os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the raw data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (26296946, 20)\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/384359\n",
    "dtypes={\n",
    "    'elapsed_time':np.int32,\n",
    "    'event_name':'category',\n",
    "    'name':'category',\n",
    "    'level':np.uint8,\n",
    "    'room_coor_x':np.float32,\n",
    "    'room_coor_y':np.float32,\n",
    "    'screen_coor_x':np.float32,\n",
    "    'screen_coor_y':np.float32,\n",
    "    'hover_duration':np.float32,\n",
    "    'text':'category',\n",
    "    'fqid':'category',\n",
    "    'room_fqid':'category',\n",
    "    'text_fqid':'category',\n",
    "    'fullscreen':'category',\n",
    "    'hq':'category',\n",
    "    'music':'category',\n",
    "    'level_group':'category'}\n",
    "\n",
    "dataset_df = pd.read_csv('data/raw/train.csv', dtype=dtypes)\n",
    "print(\"Full train dataset shape is {}\".format(dataset_df.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "          session_id  index  elapsed_time      event_name   name  level  page   \n0  20090312431273200      0             0  cutscene_click  basic      0   NaN  \\\n1  20090312431273200      1          1323    person_click  basic      0   NaN   \n2  20090312431273200      2           831    person_click  basic      0   NaN   \n3  20090312431273200      3          1147    person_click  basic      0   NaN   \n4  20090312431273200      4          1863    person_click  basic      0   NaN   \n\n   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration   \n0  -413.991394  -159.314682          380.0          494.0             NaN  \\\n1  -413.991394  -159.314682          380.0          494.0             NaN   \n2  -413.991394  -159.314682          380.0          494.0             NaN   \n3  -413.991394  -159.314682          380.0          494.0             NaN   \n4  -412.991394  -159.314682          381.0          494.0             NaN   \n\n                            text    fqid                       room_fqid   \n0                      undefined   intro  tunic.historicalsociety.closet  \\\n1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n3     I gotta run to my meeting!  gramps  tunic.historicalsociety.closet   \n4            Can I come, Gramps?  gramps  tunic.historicalsociety.closet   \n\n                                           text_fqid fullscreen hq music   \n0               tunic.historicalsociety.closet.intro          0  0     1  \\\n1  tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n2  tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n3  tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n4  tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n\n  level_group  \n0         0-4  \n1         0-4  \n2         0-4  \n3         0-4  \n4         0-4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session_id</th>\n      <th>index</th>\n      <th>elapsed_time</th>\n      <th>event_name</th>\n      <th>name</th>\n      <th>level</th>\n      <th>page</th>\n      <th>room_coor_x</th>\n      <th>room_coor_y</th>\n      <th>screen_coor_x</th>\n      <th>screen_coor_y</th>\n      <th>hover_duration</th>\n      <th>text</th>\n      <th>fqid</th>\n      <th>room_fqid</th>\n      <th>text_fqid</th>\n      <th>fullscreen</th>\n      <th>hq</th>\n      <th>music</th>\n      <th>level_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20090312431273200</td>\n      <td>0</td>\n      <td>0</td>\n      <td>cutscene_click</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-413.991394</td>\n      <td>-159.314682</td>\n      <td>380.0</td>\n      <td>494.0</td>\n      <td>NaN</td>\n      <td>undefined</td>\n      <td>intro</td>\n      <td>tunic.historicalsociety.closet</td>\n      <td>tunic.historicalsociety.closet.intro</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0-4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20090312431273200</td>\n      <td>1</td>\n      <td>1323</td>\n      <td>person_click</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-413.991394</td>\n      <td>-159.314682</td>\n      <td>380.0</td>\n      <td>494.0</td>\n      <td>NaN</td>\n      <td>Whatcha doing over there, Jo?</td>\n      <td>gramps</td>\n      <td>tunic.historicalsociety.closet</td>\n      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0-4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20090312431273200</td>\n      <td>2</td>\n      <td>831</td>\n      <td>person_click</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-413.991394</td>\n      <td>-159.314682</td>\n      <td>380.0</td>\n      <td>494.0</td>\n      <td>NaN</td>\n      <td>Just talking to Teddy.</td>\n      <td>gramps</td>\n      <td>tunic.historicalsociety.closet</td>\n      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0-4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20090312431273200</td>\n      <td>3</td>\n      <td>1147</td>\n      <td>person_click</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-413.991394</td>\n      <td>-159.314682</td>\n      <td>380.0</td>\n      <td>494.0</td>\n      <td>NaN</td>\n      <td>I gotta run to my meeting!</td>\n      <td>gramps</td>\n      <td>tunic.historicalsociety.closet</td>\n      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0-4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20090312431273200</td>\n      <td>4</td>\n      <td>1863</td>\n      <td>person_click</td>\n      <td>basic</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-412.991394</td>\n      <td>-159.314682</td>\n      <td>381.0</td>\n      <td>494.0</td>\n      <td>NaN</td>\n      <td>Can I come, Gramps?</td>\n      <td>gramps</td>\n      <td>tunic.historicalsociety.closet</td>\n      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0-4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 examples\n",
    "dataset_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "             session_id  correct            session  q\n0  20090312431273200_q1        1  20090312431273200  1\n1  20090312433251036_q1        0  20090312433251036  1\n2  20090312455206810_q1        1  20090312455206810  1\n3  20090313091715820_q1        0  20090313091715820  1\n4  20090313571836404_q1        1  20090313571836404  1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session_id</th>\n      <th>correct</th>\n      <th>session</th>\n      <th>q</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20090312431273200_q1</td>\n      <td>1</td>\n      <td>20090312431273200</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20090312433251036_q1</td>\n      <td>0</td>\n      <td>20090312433251036</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20090312455206810_q1</td>\n      <td>1</td>\n      <td>20090312455206810</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20090313091715820_q1</td>\n      <td>0</td>\n      <td>20090313091715820</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20090313571836404_q1</td>\n      <td>1</td>\n      <td>20090313571836404</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('data/raw/train_labels.csv')\n",
    "\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "\n",
    "# Display the first 5 examples\n",
    "labels.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre processing: Feature engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
    "NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y',\n",
    "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
    "\n",
    "# Reference: https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n",
    "\n",
    "def feature_engineer(dataset_df):\n",
    "    dfs = []\n",
    "    for c in CATEGORICAL:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n",
    "        tmp.name = tmp.name + '_nunique'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMERICAL:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMERICAL:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n",
    "        tmp.name = tmp.name + '_std'\n",
    "        dfs.append(tmp)\n",
    "    dataset_df = pd.concat(dfs,axis=1)\n",
    "    dataset_df = dataset_df.fillna(-1)\n",
    "    dataset_df = dataset_df.reset_index()\n",
    "    dataset_df = dataset_df.set_index('session_id')\n",
    "    return dataset_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full prepared dataset shape is (70686, 22)\n"
     ]
    }
   ],
   "source": [
    "dataset_df = feature_engineer(dataset_df)\n",
    "print(\"Full prepared dataset shape is {}\".format(dataset_df.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56547 examples in training, 14139 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "    USER_LIST = dataset_df.index.unique()\n",
    "    split = int(len(USER_LIST) * (1 - test_ratio))\n",
    "    return dataset.loc[USER_LIST[:split]], dataset.loc[USER_LIST[split:]]\n",
    "\n",
    "train_x, valid_x = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_x), len(valid_x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Fetch the unique list of user sessions in the validation dataset. We assigned\n",
    "# `session_id` as the index of our feature engineered dataset. Hence fetching\n",
    "# the unique values in the index column will give us a list of users in the\n",
    "# validation set.\n",
    "VALID_USER_LIST = valid_x.index.unique()\n",
    "\n",
    "# Create a dataframe for storing the predictions of each question for all users\n",
    "# in the validation set.\n",
    "# For this, the required size of the data frame is:\n",
    "# (no: of users in validation set  x no of questions).\n",
    "# We will initialize all the predicted values in the data frame to zero.\n",
    "# The dataframe's index column is the user `session_id`s.\n",
    "prediction_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
    "\n",
    "# Create an empty dictionary to store the models created for each question.\n",
    "models = {}\n",
    "\n",
    "# Create an empty dictionary to store the evaluation score for each question.\n",
    "evaluation_dict ={}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### q_no 1 grp 0-4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "X is not of a supported input data type.X must be in a supported mtype format for Panel, found <class 'pandas.core.frame.DataFrame'>Use datatypes.check_is_mtype to check conformance with specifications.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 55\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# There's one more step required before we can train the model.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# We need to convert the datatset from Pandas format (pd.DataFrame)\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# into TensorFlow Datasets format (tf.data.Dataset).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     50\u001B[0m \n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m#models[f'{grp}_{q_no}'] = gbtm\u001B[39;00m\n\u001B[1;32m     53\u001B[0m rocket1 \u001B[38;5;241m=\u001B[39m RocketClassifier()\n\u001B[0;32m---> 55\u001B[0m \u001B[43mrocket1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m rocket_preds \u001B[38;5;241m=\u001B[39m rocket1\u001B[38;5;241m.\u001B[39mpredict(X_val)\n\u001B[1;32m     58\u001B[0m accuracy_temp \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39maccuracy_score(y_val, rocket_preds)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/gameplay_kaggel_env/lib/python3.9/site-packages/sktime/classification/base.py:167\u001B[0m, in \u001B[0;36mBaseClassifier.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;66;03m# convenience conversions to allow user flexibility:\u001B[39;00m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;66;03m# if X is 2D array, convert to 3D, if y is Series, convert to numpy\u001B[39;00m\n\u001B[1;32m    166\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_convert(X, y)\n\u001B[0;32m--> 167\u001B[0m X_metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_classifier_input\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMETADATA_REQ_IN_CHECKS\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m missing \u001B[38;5;241m=\u001B[39m X_metadata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_nans\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    171\u001B[0m multivariate \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m X_metadata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_univariate\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/gameplay_kaggel_env/lib/python3.9/site-packages/sktime/classification/base.py:722\u001B[0m, in \u001B[0;36mBaseClassifier._check_classifier_input\u001B[0;34m(self, X, y, enforce_min_instances, return_metadata)\u001B[0m\n\u001B[1;32m    718\u001B[0m X_valid, _, X_metadata \u001B[38;5;241m=\u001B[39m check_is_scitype(\n\u001B[1;32m    719\u001B[0m     X, scitype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPanel\u001B[39m\u001B[38;5;124m\"\u001B[39m, return_metadata\u001B[38;5;241m=\u001B[39mreturn_metadata\n\u001B[1;32m    720\u001B[0m )\n\u001B[1;32m    721\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m X_valid:\n\u001B[0;32m--> 722\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    723\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX is not of a supported input data type.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    724\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX must be in a supported mtype format for Panel, found \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(X)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    725\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse datatypes.check_is_mtype to check conformance \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    726\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith specifications.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    727\u001B[0m     )\n\u001B[1;32m    728\u001B[0m n_cases \u001B[38;5;241m=\u001B[39m X_metadata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_instances\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    729\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_cases \u001B[38;5;241m<\u001B[39m enforce_min_instances:\n",
      "\u001B[0;31mTypeError\u001B[0m: X is not of a supported input data type.X must be in a supported mtype format for Panel, found <class 'pandas.core.frame.DataFrame'>Use datatypes.check_is_mtype to check conformance with specifications."
     ]
    }
   ],
   "source": [
    "# Iterate through questions 1 to 18 to train models for each question, evaluate\n",
    "# the trained model and store the predicted values.\n",
    "for q_no in range(1,19):\n",
    "\n",
    "    # Select level group for the question based on the q_no.\n",
    "    if q_no<=3: grp = '0-4'\n",
    "    elif q_no<=13: grp = '5-12'\n",
    "    elif q_no<=22: grp = '13-22'\n",
    "    print(\"### q_no\", q_no, \"grp\", grp)\n",
    "\n",
    "    # Filter the rows in the datasets based on the selected level group.\n",
    "    X_train = train_x.loc[train_x.level_group == grp]\n",
    "    train_users = X_train.index.values\n",
    "    X_val = valid_x.loc[valid_x.level_group == grp]\n",
    "    valid_users = X_val.index.values\n",
    "\n",
    "    # Select the labels for the related q_no.\n",
    "    train_labels = labels.loc[labels.q==q_no].set_index('session').loc[train_users]\n",
    "    valid_labels = labels.loc[labels.q==q_no].set_index('session').loc[valid_users]\n",
    "\n",
    "    # Add the label to the filtered datasets.\n",
    "\n",
    "    #train_df[\"correct\"] = train_labels[\"correct\"]\n",
    "    #valid_df[\"correct\"] = valid_labels[\"correct\"]\n",
    "\n",
    "    y_train = train_labels[\"correct\"]\n",
    "    y_val = valid_labels[\"correct\"]\n",
    "\n",
    "    # There's one more step required before we can train the model.\n",
    "    # We need to convert the datatset from Pandas format (pd.DataFrame)\n",
    "    # into TensorFlow Datasets format (tf.data.Dataset).\n",
    "    # TensorFlow Datasets is a high performance data loading library\n",
    "    # which is helpful when training neural networks with accelerators like GPUs and TPUs.\n",
    "    # We are omitting `level_group`, since it is not needed for training anymore.\n",
    "\n",
    "    #train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df.loc[:, train_df.columns != 'level_group'], label=\"correct\")\n",
    "    #valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_df.loc[:, valid_df.columns != 'level_group'], label=\"correct\")\n",
    "\n",
    "    # We will now create the Gradient Boosted Trees Model with default settings.\n",
    "    # By default the model is set to train for a classification task.\n",
    "\n",
    "    #gbtm = tfdf.keras.GradientBoostedTreesModel(verbose=0)\n",
    "    #gbtm.compile(metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train the model.\n",
    "\n",
    "    #gbtm.fit(x=train_ds)\n",
    "\n",
    "    # Store the model\n",
    "\n",
    "    #models[f'{grp}_{q_no}'] = gbtm\n",
    "\n",
    "    rocket1 = RocketClassifier()\n",
    "\n",
    "    rocket1.fit(X_train, y_train)\n",
    "\n",
    "    rocket_preds = rocket1.predict(X_val)\n",
    "    accuracy_temp = metrics.accuracy_score(y_val, rocket_preds)\n",
    "    print(str(q_no) + \" - Rocket Accuracy: \" + str(accuracy_temp))\n",
    "    print(str(q_no) + \" - Rocket Accuracy: \" + str(metrics.f1_score(y_val, rocket_preds)))\n",
    "\n",
    "    # Evaluate the trained model on the validation dataset and store the\n",
    "    # evaluation accuracy in the `evaluation_dict`.\n",
    "\n",
    "    #inspector = gbtm.make_inspector()\n",
    "    #inspector.evaluation()\n",
    "    #evaluation = gbtm.evaluate(x=valid_ds,return_dict=True)\n",
    "    evaluation_dict[q_no] = accuracy_temp\n",
    "\n",
    "    # Use the trained model to make predictions on the validation dataset and\n",
    "    # store the predicted values in the `prediction_df` dataframe.\n",
    "\n",
    "    #predict = gbtm.predict(x=valid_ds)\n",
    "    prediction_df.loc[valid_users, q_no-1] = rocket_preds.flatten() # WARNING: .flatten compatible?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18849, 22) (18849,) (4713, 22) (4713,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, value in evaluation_dict.items():\n",
    "  print(f\"question {name}: accuracy {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage accuracy\", sum(evaluation_dict.values())/18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "cv3 = StratifiedShuffleSplit(n_splits=6, train_size=0.75, random_state=42)\n",
    "cv_results3 = cross_val_score(rocket1, X=X1, y=y1, cv=cv3)\n",
    "\n",
    "print(cv_results3)\n",
    "print(str(cv_results3.mean()) + \" +/-\" + str(cv_results3.std()))\n",
    "rocket_preds3 = rocket1.predict(X_test1)\n",
    "print(\"Rocket Accuracy: \" + str(metrics.accuracy_score(y_test1, rocket_preds3)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay.from_predictions(y_test1, rocket_preds, display_labels=rocket1.classes_, xticks_rotation='45')\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "disp.plot(ax=ax)\n",
    "plt.show()\n",
    "disp.ax_.set_title('The Rocket Algorithm')\n",
    "print('The Rocket Algorithm')\n",
    "print(disp.confusion_matrix)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}