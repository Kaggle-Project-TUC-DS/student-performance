{"cells":[{"cell_type":"markdown","metadata":{"id":"zAXHC6-Tn2O5"},"source":["# Import the Required Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T14:09:53.548383Z","iopub.status.busy":"2023-04-11T14:09:53.548001Z","iopub.status.idle":"2023-04-11T14:10:03.418306Z","shell.execute_reply":"2023-04-11T14:10:03.416814Z","shell.execute_reply.started":"2023-04-11T14:09:53.548350Z"},"id":"IanlX-Eqn2O5","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-04 09:28:25.113805: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-05-04 09:28:25.585390: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-05-04 09:28:25.591157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-04 09:28:29.257023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/home/joh/student-performance/.venv/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","import tensorflow_decision_forests as tfdf\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T13:43:31.244392Z","iopub.status.busy":"2023-04-11T13:43:31.243601Z","iopub.status.idle":"2023-04-11T13:43:31.250965Z","shell.execute_reply":"2023-04-11T13:43:31.249810Z","shell.execute_reply.started":"2023-04-11T13:43:31.244354Z"},"id":"gLpK2yAen2O7","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow Decision Forests v1.3.0\n","TensorFlow Addons v0.20.0\n","TensorFlow v2.12.0\n","Working Directory:  /home/joh\n"]}],"source":["print(\"TensorFlow Decision Forests v\" + tfdf.__version__)\n","print(\"TensorFlow Addons v\" + tfa.__version__)\n","print(\"TensorFlow v\" + tf.__version__)\n","# get working directory and remove last folder\n","wd = os.path.dirname(os.getcwd())\n","os.chdir(wd)\n","print(\"Working Directory: \", os.getcwd())"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T14:10:22.591769Z","iopub.status.busy":"2023-04-11T14:10:22.591365Z","iopub.status.idle":"2023-04-11T14:12:32.862280Z","shell.execute_reply":"2023-04-11T14:12:32.861013Z","shell.execute_reply.started":"2023-04-11T14:10:22.591735Z"},"id":"_XItl24kn2O7","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Full train dataset shape is (26296946, 20)\n"]}],"source":["# Reference: https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/384359\n","dtypes={\n","    'elapsed_time':np.int32,\n","    'event_name':'category',\n","    'name':'category',\n","    'level':np.uint8,\n","    'room_coor_x':np.float32,\n","    'room_coor_y':np.float32,\n","    'screen_coor_x':np.float32,\n","    'screen_coor_y':np.float32,\n","    'hover_duration':np.float32,\n","    'text':'category',\n","    'fqid':'category',\n","    'room_fqid':'category',\n","    'text_fqid':'category',\n","    'fullscreen':'category',\n","    'hq':'category',\n","    'music':'category',\n","    'level_group':'category'}\n","\n","dataset_df = pd.read_csv('/home/joh/student-performance/data/raw/train.csv', dtype=dtypes)\n","print(\"Full train dataset shape is {}\".format(dataset_df.shape))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ReNY-i3bn2O8"},"source":["# Load the labels"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T14:21:38.653150Z","iopub.status.busy":"2023-04-11T14:21:38.652683Z","iopub.status.idle":"2023-04-11T14:21:39.150996Z","shell.execute_reply":"2023-04-11T14:21:39.149727Z","shell.execute_reply.started":"2023-04-11T14:21:38.653109Z"},"id":"KD4uayl2n2O9","trusted":true},"outputs":[],"source":["labels = pd.read_csv('/home/joh/student-performance/data/raw/train_labels.csv')"]},{"cell_type":"markdown","metadata":{"id":"SMKh2KAPn2O9"},"source":["Each value in the column, `session_id` is a combination of both the session and the question number. \n","We will split these into individual columns for ease of use."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T14:21:58.714590Z","iopub.status.busy":"2023-04-11T14:21:58.713303Z","iopub.status.idle":"2023-04-11T14:21:59.500756Z","shell.execute_reply":"2023-04-11T14:21:59.499370Z","shell.execute_reply.started":"2023-04-11T14:21:58.714543Z"},"id":"Kva8_Dbqn2O9","trusted":true},"outputs":[],"source":["labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n","labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )"]},{"cell_type":"markdown","metadata":{"id":"y5fK05dsn2O_"},"source":["# Prepare the dataset\n","\n","As summarized in the competition overview, the dataset presents the questions and data to us in order of `levels - level segments`(represented by column `level_group`) 0-4, 5-12, and 13-22. We have to predict the correctness of each segment's questions as they are presented. To do this we will create basic aggregate features from the relevant columns. You can create more features to boost your scores. \n","\n","First, we will create two separate lists with names of the Categorical columns and Numerical columns. We will avoid columns `fullscreen`, `hq` and `music` since they don't add any useful value for this problem statement."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T14:23:53.358071Z","iopub.status.busy":"2023-04-11T14:23:53.357578Z","iopub.status.idle":"2023-04-11T14:23:53.363563Z","shell.execute_reply":"2023-04-11T14:23:53.362389Z","shell.execute_reply.started":"2023-04-11T14:23:53.358029Z"},"id":"cCZWGiL_n2PA","trusted":true},"outputs":[],"source":["CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid', 'fullscreen', 'hq', 'music']\n","NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y', \n","        'screen_coor_x', 'screen_coor_y', 'hover_duration']"]},{"cell_type":"markdown","metadata":{"id":"Us9sScDSn2PA"},"source":["For each categorical column, we will first group the dataset by `session_id`  and `level_group`. We will then count the number of **distinct elements** in the column for each group and store it temporarily.\n","\n","For all numerical columns, we will group the dataset by `session id` and `level_group`. Instead of counting the number of distinct elements, we will calculate the `mean` and `standard deviation` of the numerical column for each group and store it temporarily.\n","\n","After this, we will concatenate the temporary data frames we generated in the earlier step for each column to create our new feature engineered dataset."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T14:24:34.807934Z","iopub.status.busy":"2023-04-11T14:24:34.807357Z","iopub.status.idle":"2023-04-11T14:24:34.819191Z","shell.execute_reply":"2023-04-11T14:24:34.818058Z","shell.execute_reply.started":"2023-04-11T14:24:34.807863Z"},"id":"nHWhAOtTn2PA","trusted":true},"outputs":[],"source":["# Reference: https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n","\n","def feature_engineer(dataset_df):\n","    dfs = []\n","    #for c in CATEGORICAL:\n","    #    tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n","    #    tmp.name = tmp.name + '_nunique'\n","    #    dfs.append(tmp)\n","    for c in CATEGORICAL:\n","        if c not in ['fullscreen', 'hq', 'music']:\n","            tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n","        else:\n","            tmp = dataset_df.groupby(['session_id','level_group'])[c].first()\n","        dfs.append(tmp)\n","    #return pd.concat(dfs, axis=1)\n","    for c in NUMERICAL:\n","        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n","        tmp.name = tmp.name + '_mean'\n","        dfs.append(tmp)\n","    for c in NUMERICAL:\n","        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n","        tmp.name = tmp.name + '_std'\n","        dfs.append(tmp)\n","    dataset_df = pd.concat(dfs,axis=1)\n","    dataset_df = dataset_df.fillna(-1)\n","    dataset_df = dataset_df.reset_index()\n","    dataset_df = dataset_df.set_index('session_id')\n","    return dataset_df"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-04-11T14:28:01.122665Z","iopub.status.busy":"2023-04-11T14:28:01.122096Z","iopub.status.idle":"2023-04-11T14:28:41.731564Z","shell.execute_reply":"2023-04-11T14:28:41.730639Z","shell.execute_reply.started":"2023-04-11T14:28:01.122597Z"},"id":"JKcoPoemn2PA","trusted":true},"outputs":[{"ename":"TypeError","evalue":"Cannot setitem on a Categorical with a new category (-1), set the categories first","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_df_fengineered \u001b[39m=\u001b[39m feature_engineer(dataset_df)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFull prepared dataset shape is \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(dataset_df_fengineered\u001b[39m.\u001b[39mshape))\n","Cell \u001b[0;32mIn[22], line 25\u001b[0m, in \u001b[0;36mfeature_engineer\u001b[0;34m(dataset_df)\u001b[0m\n\u001b[1;32m     23\u001b[0m     dfs\u001b[39m.\u001b[39mappend(tmp)\n\u001b[1;32m     24\u001b[0m dataset_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m dataset_df \u001b[39m=\u001b[39m dataset_df\u001b[39m.\u001b[39;49mfillna(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m dataset_df \u001b[39m=\u001b[39m dataset_df\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     27\u001b[0m dataset_df \u001b[39m=\u001b[39m dataset_df\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39msession_id\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[0;32m~/student-performance/.venv/lib/python3.10/site-packages/pandas/core/frame.py:5503\u001b[0m, in \u001b[0;36mDataFrame.fillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   5492\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39mfillna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_shared_doc_kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfillna\u001b[39m(\n\u001b[1;32m   5494\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5501\u001b[0m     downcast: \u001b[39mdict\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   5502\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 5503\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfillna(\n\u001b[1;32m   5504\u001b[0m         value\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m   5505\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   5506\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5507\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5508\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[1;32m   5509\u001b[0m         downcast\u001b[39m=\u001b[39;49mdowncast,\n\u001b[1;32m   5510\u001b[0m     )\n","File \u001b[0;32m~/student-performance/.venv/lib/python3.10/site-packages/pandas/core/generic.py:6983\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   6981\u001b[0m         new_data \u001b[39m=\u001b[39m result\n\u001b[1;32m   6982\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 6983\u001b[0m         new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mfillna(\n\u001b[1;32m   6984\u001b[0m             value\u001b[39m=\u001b[39;49mvalue, limit\u001b[39m=\u001b[39;49mlimit, inplace\u001b[39m=\u001b[39;49minplace, downcast\u001b[39m=\u001b[39;49mdowncast\n\u001b[1;32m   6985\u001b[0m         )\n\u001b[1;32m   6986\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, ABCDataFrame) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   6987\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhere(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotna(), value)\u001b[39m.\u001b[39m_mgr\n","File \u001b[0;32m~/student-performance/.venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:433\u001b[0m, in \u001b[0;36mBaseBlockManager.fillna\u001b[0;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39mif\u001b[39;00m limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m     \u001b[39m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     limit \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mvalidate_limit(\u001b[39mNone\u001b[39;00m, limit\u001b[39m=\u001b[39mlimit)\n\u001b[0;32m--> 433\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mfillna\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    435\u001b[0m     value\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m    436\u001b[0m     limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[1;32m    437\u001b[0m     inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m    438\u001b[0m     downcast\u001b[39m=\u001b[39;49mdowncast,\n\u001b[1;32m    439\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[1;32m    440\u001b[0m )\n","File \u001b[0;32m~/student-performance/.venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    353\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    355\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n","File \u001b[0;32m~/student-performance/.venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1866\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[0;34m(self, value, limit, inplace, downcast, using_cow)\u001b[0m\n\u001b[1;32m   1864\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1865\u001b[0m     refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1866\u001b[0m     new_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mfillna(value\u001b[39m=\u001b[39;49mvalue, method\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[1;32m   1867\u001b[0m nb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block_same_class(new_values, refs\u001b[39m=\u001b[39mrefs)\n\u001b[1;32m   1868\u001b[0m \u001b[39mreturn\u001b[39;00m nb\u001b[39m.\u001b[39m_maybe_downcast([nb], downcast, using_cow\u001b[39m=\u001b[39musing_cow)\n","File \u001b[0;32m~/student-performance/.venv/lib/python3.10/site-packages/pandas/core/arrays/_mixins.py:328\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.fillna\u001b[0;34m(self, value, method, limit)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_setitem_value(value)\n\u001b[1;32m    330\u001b[0m     new_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    331\u001b[0m \u001b[39mreturn\u001b[39;00m new_values\n","File \u001b[0;32m~/student-performance/.venv/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:1297\u001b[0m, in \u001b[0;36mCategorical._validate_setitem_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_listlike(value)\n\u001b[1;32m   1296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_scalar(value)\n","File \u001b[0;32m~/student-performance/.venv/lib/python3.10/site-packages/pandas/core/arrays/categorical.py:1322\u001b[0m, in \u001b[0;36mCategorical._validate_scalar\u001b[0;34m(self, fill_value)\u001b[0m\n\u001b[1;32m   1320\u001b[0m     fill_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unbox_scalar(fill_value)\n\u001b[1;32m   1321\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1322\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1323\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot setitem on a Categorical with a new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1324\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategory (\u001b[39m\u001b[39m{\u001b[39;00mfill_value\u001b[39m}\u001b[39;00m\u001b[39m), set the categories first\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1325\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[39mreturn\u001b[39;00m fill_value\n","\u001b[0;31mTypeError\u001b[0m: Cannot setitem on a Categorical with a new category (-1), set the categories first"]}],"source":["dataset_df_fengineered = feature_engineer(dataset_df)\n","print(\"Full prepared dataset shape is {}\".format(dataset_df_fengineered.shape))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"891j7nc1n2PA"},"source":["Our feature engineered dataset is composed of 25 columns and 70686 entries. "]}],"metadata":{"kernelspec":{"display_name":"tf_df","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
