{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory:  c:\\Users\\Stephan\\Documents\\Python\\Python-Stat\\Neuer\\Kaggle_semiinar\\student-performance\n"
     ]
    }
   ],
   "source": [
    "#set working directory\n",
    "wd = os.path.dirname(os.getcwd())\n",
    "os.chdir(wd)\n",
    "print(\"Working Directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('data/raw/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the now obsolete labels of the labels\n",
    "labels= labels.set_index('session')\n",
    "labels = labels.drop([\"session_id\"], axis= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataset\n",
    "\n",
    "\n",
    "\n",
    "labels.to_csv(\"data/processed/labels.csv\",index_label= \"session\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataframe labels is saved. \n",
    "it contains the cols:\n",
    " session : the session id\n",
    " correct : 0 and 1 for the answer of the question\n",
    " q: number of the question from 1 to 18\n",
    "\n",
    "The Data are stored as a .csv  \n",
    "\n",
    "to load the data efficiently use this loading function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_labels= {\n",
    "    'correct': np.uint8, \n",
    "    'q':np.uint8}\n",
    "\n",
    "labels = pd.read_csv('data/processed/labels_q1-3.csv', dtype=dtypes_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(file_path: str , dtypes: dict = None, n_rows: int = None):\n",
    "    # If dtypes is not specified, set default data types for each column\n",
    "    if dtypes is None:\n",
    "        dtypes = {\n",
    "            'level': np.uint8,  \n",
    "            'session_id': np.int64,\n",
    "            'level_group': 'category',\n",
    "            'event_name': np.uint8,\n",
    "            'name': np.uint8,\n",
    "            'fqid': np.uint8,\n",
    "            'room_fqid': np.uint8,\n",
    "            'text_fqid': np.uint8,\n",
    "            'fullscreen': np.uint8,\n",
    "            'hq': np.uint8,\n",
    "            'music': np.uint8,\n",
    "            'hover_duration_mean': np.float32,\n",
    "            'difference_clicks_mean': np.float32,\n",
    "            \"distance_clicks_mean\": np.float32,\n",
    "            \"screen_distance_clicks_mean\": np.float32,            \n",
    "            'elapsed_time_std': np.float32,\n",
    "            'page_std': np.float32,\n",
    "            'room_coor_x_std': np.float32,\n",
    "            'room_coor_y_std': np.float32,\n",
    "            'screen_coor_x_std': np.float32,\n",
    "            'screen_coor_y_std': np.float32,\n",
    "            'hover_duration_std': np.float32,\n",
    "            'difference_clicks_std': np.float32,\n",
    "            \"distance_clicks_std\": np.float32,\n",
    "            \"screen_distance_clicks_std\": np.float32,\n",
    "            'index_sum_of_actions': np.int32,\n",
    "            'difference_clicks_max': np.float32,\n",
    "            'elapsed_time_max': np.float32,\n",
    "            'clicks_per_second': np.float32,\n",
    "            \"sum_distance_clicks_max\": np.float32,\n",
    "        }\n",
    "        \n",
    "    # Read in the CSV file\n",
    "    if n_rows is None:\n",
    "        df = pd.read_csv(file_path, dtype=dtypes, index_col = 0)\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, dtype=dtypes, nrows=n_rows, index_col= 0)\n",
    "    \n",
    "    # Set data types for columns with \"_i\" index in their name\n",
    "    row, cols = df.shape\n",
    "    if cols > 50:\n",
    "        for column in df.columns:\n",
    "            base_name = column.rsplit('_', 1)[0]  # get the base name by splitting on the last \"_\" character\n",
    "            if base_name in dtypes:\n",
    "                column_number = column.rsplit('_', 1)[1]  # get the number from the index by splitting on the last \"_\" character\n",
    "                new_column_name = f\"{base_name}_{column_number}\"  # construct the new column name\n",
    "                column_dtype = dtypes[base_name]\n",
    "                df[new_column_name] = df[column].astype(column_dtype)  # set the same data type for all columns with the same base name\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_train_data(\"data/processed/df_0_4_flattened.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stephan\\AppData\\Local\\Temp\\ipykernel_10904\\2422067669.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels_q2.rename(columns= {\"session\": \"session_id_1\"}, inplace= True)\n"
     ]
    }
   ],
   "source": [
    "labels_q2 = labels[labels[\"q\"] == 2]\n",
    "labels_q2.rename(columns= {\"session\": \"session_id_1\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(labels_q2, train_data, on='session_id_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merged_df[\"correct\"]\n",
    "X = merged_df.drop(columns=[\"session_id_1\", \"level_group_1\", \"q\", \"correct\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "737/737 [==============================] - 7s 6ms/step - loss: 21366600368128.0000 - accuracy: 0.9570\n",
      "Epoch 2/10\n",
      "737/737 [==============================] - 4s 5ms/step - loss: 17725309059072.0000 - accuracy: 0.9581\n",
      "Epoch 3/10\n",
      "737/737 [==============================] - 4s 5ms/step - loss: 13866495901696.0000 - accuracy: 0.9580\n",
      "Epoch 4/10\n",
      "737/737 [==============================] - 3s 4ms/step - loss: 7615312035840.0000 - accuracy: 0.9593\n",
      "Epoch 5/10\n",
      "737/737 [==============================] - 3s 5ms/step - loss: 5237923381248.0000 - accuracy: 0.9580\n",
      "Epoch 6/10\n",
      "737/737 [==============================] - 3s 4ms/step - loss: 4276999684096.0000 - accuracy: 0.9580\n",
      "Epoch 7/10\n",
      "737/737 [==============================] - 4s 6ms/step - loss: 3256495636480.0000 - accuracy: 0.9579\n",
      "Epoch 8/10\n",
      "737/737 [==============================] - 4s 6ms/step - loss: 2474828627968.0000 - accuracy: 0.9582\n",
      "Epoch 9/10\n",
      "737/737 [==============================] - 4s 6ms/step - loss: 3916167905280.0000 - accuracy: 0.9571\n",
      "Epoch 10/10\n",
      "737/737 [==============================] - 5s 7ms/step - loss: 1943816896512.0000 - accuracy: 0.9588\n",
      "737/737 [==============================] - 4s 5ms/step\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Assuming you have a matrix of features called \"X\" (shape: [n_samples, 111]) and\n",
    "# a target column called \"correct\" (shape: [n_samples]).\n",
    "\n",
    "# Define the number of input features\n",
    "input_dim = 107\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print predictions\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
