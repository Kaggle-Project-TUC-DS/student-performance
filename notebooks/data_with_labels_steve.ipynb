{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports for the Data Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import gc\n",
    "from typing import Tuple\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory:  n:\\MASTER_DS\\Code\\Kaggle_competition\\Kaggle-seminar\\student-performance\n"
     ]
    }
   ],
   "source": [
    "# get working directory and remove last folder\n",
    "# TODO: make this more robust\n",
    "wd = os.path.dirname(os.getcwd())\n",
    "os.chdir(wd)\n",
    "print('Working Directory: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one cell to load the train and label data\n",
    "def load_train_data(file_path: str , dtypes: dict = None, n_rows: int = None):\n",
    "    # If dtypes is not specified, set default data types for each column\n",
    "    if dtypes is None:\n",
    "        dtypes = {\n",
    "            'level': np.uint8,  \n",
    "            'session_id': np.int64,\n",
    "            'level_group': 'category',\n",
    "            'event_name': np.uint8,\n",
    "            'name': np.uint8,\n",
    "            'fqid': np.uint8,\n",
    "            'room_fqid': np.uint8,\n",
    "            'text_fqid': np.uint8,\n",
    "            'fullscreen': np.uint8,\n",
    "            'hq': np.uint8,\n",
    "            'music': np.uint8,\n",
    "            'hover_duration_mean': np.float32,\n",
    "            'difference_clicks_mean': np.float32,\n",
    "            \"distance_clicks_mean\": np.float32,\n",
    "            \"screen_distance_clicks_mean\": np.float32,            \n",
    "            'elapsed_time_std': np.float32,\n",
    "            'page_std': np.float32,\n",
    "            'room_coor_x_std': np.float32,\n",
    "            'room_coor_y_std': np.float32,\n",
    "            'screen_coor_x_std': np.float32,\n",
    "            'screen_coor_y_std': np.float32,\n",
    "            'hover_duration_std': np.float32,\n",
    "            'difference_clicks_std': np.float32,\n",
    "            \"distance_clicks_std\": np.float32,\n",
    "            \"screen_distance_clicks_std\": np.float32,\n",
    "            'index_sum_of_actions': np.int32,\n",
    "            'difference_clicks_max': np.float32,\n",
    "            'elapsed_time_max': np.float32,\n",
    "            'clicks_per_second': np.float32,\n",
    "            \"sum_distance_clicks_max\": np.float32,\n",
    "        }\n",
    "        \n",
    "    # Read in the CSV file\n",
    "    if n_rows is None:\n",
    "        df = pd.read_csv(file_path, dtype=dtypes, index_col = 0)\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, dtype=dtypes, nrows=n_rows, index_col= 0)\n",
    "    \n",
    "    # Set data types for columns with \"_i\" index in their name\n",
    "    row, cols = df.shape\n",
    "    if cols > 50:\n",
    "        for column in df.columns:\n",
    "            base_name = column.rsplit('_', 1)[0]  # get the base name by splitting on the last \"_\" character\n",
    "            if base_name in dtypes:\n",
    "                column_number = column.rsplit('_', 1)[1]  # get the number from the index by splitting on the last \"_\" character\n",
    "                new_column_name = f\"{base_name}_{column_number}\"  # construct the new column name\n",
    "                column_dtype = dtypes[base_name]\n",
    "                df[new_column_name] = df[column].astype(column_dtype)  # set the same data type for all columns with the same base name\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_train_data(\"data/processed/df_5_12_flattened.csv\")\n",
    "dtypes_labels= {\n",
    "    'correct': np.uint8, \n",
    "    'q':np.uint8}\n",
    "\n",
    "labels = pd.read_csv('data/processed/labels_q4-13.csv', dtype=dtypes_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(train_data, labels, left_on='session_id_1',\n",
    "                     right_on='session', how='inner')\n",
    "merged_df.drop(['session_id_1', 'session'], axis=1, inplace=True)\n",
    "grouped_df = merged_df.groupby('q')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_class_weight() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mn:\\MASTER_DS\\Code\\Kaggle_competition\\Kaggle-seminar\\student-performance\\notebooks\\data_with_labels_steve.ipynb Cell 6\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/data_with_labels_steve.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m class_weight\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/data_with_labels_steve.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Calculate class weights\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/data_with_labels_steve.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m class_weights \u001b[39m=\u001b[39m class_weight\u001b[39m.\u001b[39mcompute_class_weight(\u001b[39m'\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39munique(y_train), y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/data_with_labels_steve.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m question, group \u001b[39min\u001b[39;00m grouped_df:\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/data_with_labels_steve.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# Access the features and labels for the current question\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/data_with_labels_steve.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     X \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcorrect\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlevel_group_1\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: compute_class_weight() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import numpy as np\n",
    "# Dictionary to store the models\n",
    "models = {}\n",
    "\n",
    "# Hyperparameters\n",
    "hidden_units = [512, 256, 128]\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "for question, group in grouped_df:\n",
    "    # Access the features and labels for the current question\n",
    "    X = group.drop(['q', 'correct', 'level_group_1'], axis=1)\n",
    "    y = group['correct']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Calculate class weights for the current question\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "\n",
    "    # Define the MLP architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units[0], activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(hidden_units[1], activation='relu'))\n",
    "    model.add(Dense(hidden_units[2], activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with class weights\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with class weights\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, class_weight=class_weights, verbose=0)\n",
    "\n",
    "    # Store the model in the dictionary\n",
    "    models[question] = model\n",
    "\n",
    "    # Evaluate the model on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5)  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print('Question:', question)\n",
    "    print('F1 Score:', f1)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
