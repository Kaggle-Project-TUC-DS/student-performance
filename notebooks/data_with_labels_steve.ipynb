{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports for the Data Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import gc\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory:  c:\\Users\\Stephan\\Documents\\Python\\Python-Stat\\Neuer\\Kaggle_semiinar\\student-performance\n"
     ]
    }
   ],
   "source": [
    "# get working directory and remove last folder\n",
    "# TODO: make this more robust\n",
    "wd = os.path.dirname(os.getcwd())\n",
    "os.chdir(wd)\n",
    "print('Working Directory: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'level': np.uint8,\n",
    "    \"level_group\": \"category\",\n",
    "    'event_name': np.uint8,\n",
    "    'name': np.uint8,\n",
    "    'fqid': np.uint8,\n",
    "    'room_fqid': np.uint8,           \n",
    "    \"text_fqid\": np.uint8,\n",
    "    'fullscreen': np.uint8,\n",
    "    'hq': np.uint8,\n",
    "    'music': np.uint8,\n",
    "    'hover_duration_mean': np.float32,\n",
    "    'difference_clicks_mean': np.float32,\n",
    "    'elapsed_time_std': np.float32,\n",
    "    'page_std': np.float32,\n",
    "    'room_coor_x_std': np.float32,\n",
    "    'room_coor_y_std': np.float32,\n",
    "    'screen_coor_x_std': np.float32,\n",
    "    'screen_coor_y_std': np.float32,\n",
    "    'hover_duration_std': np.float32,\n",
    "    'difference_clicks_std': np.float32,\n",
    "    'index_sum_of_actions': np.float32,\n",
    "    'difference_clicks_max': np.float32,\n",
    "    'elapsed_time_max': np.float32,\n",
    "    'clicks_per_second': np.float32}\n",
    "\n",
    "dataset_df = pd.read_csv(\"data/processed/dataset_df_level.csv\", dtype=dtypes)\n",
    "\n",
    "#load the label dataset\n",
    "#labels = pd.read_csv(\"data/processed/labels.csv\")\n",
    "dataset_df_0_4 = pd.read_csv(\"data/processed/df_0_4.csv\", dtype=dtypes, index_col= 0)\n",
    "dataset_df_0_4 = dataset_df_0_4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "    USER_LIST = dataset_df.index.unique()\n",
    "    split = int(len(USER_LIST) * (1 - 0.20))\n",
    "    return dataset.loc[USER_LIST[:split]], dataset.loc[USER_LIST[split:]]\n",
    "\n",
    "train_x, valid_x = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_x), len(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the unique list of user sessions in the validation dataset. We assigned \n",
    "# `session_id` as the index of our feature engineered dataset. Hence fetching \n",
    "# the unique values in the index column will give us a list of users in the \n",
    "# validation set.\n",
    "VALID_USER_LIST = valid_x.index.unique()\n",
    "\n",
    "# Create a dataframe for storing the predictions of each question for all users\n",
    "# in the validation set.\n",
    "# For this, the required size of the data frame is: \n",
    "# (no: of users in validation set  x no of questions).\n",
    "# We will initialize all the predicted values in the data frame to zero.\n",
    "# The dataframe's index column is the user `session_id`s. \n",
    "prediction_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
    "\n",
    "# Create an empty dictionary to store the models created for each question.\n",
    "models = {}\n",
    "\n",
    "# Create an empty dictionary to store the evaluation score for each question.\n",
    "evaluation_dict ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get labels and data together\n",
    "# Iterate through questions 1 to 18 to train models for each question, evaluate\n",
    "# the trained model and store the predicted values.\n",
    "for q_no in range(1,19):\n",
    "\n",
    "    # Select level group for the question based on the q_no.\n",
    "    if q_no<=3: grp = '0-4'\n",
    "    elif q_no<=13: grp = '5-12'\n",
    "    elif q_no<=22: grp = '13-22'\n",
    "    print(\"### q_no\", q_no, \"grp\", grp)\n",
    "    \n",
    "        \n",
    "    # Filter the rows in the datasets based on the selected level group. \n",
    "    train_df = train_x.loc[train_x.level_group == grp]\n",
    "    train_users = train_df.index.values\n",
    "    valid_df = valid_x.loc[valid_x.level_group == grp]\n",
    "    valid_users = valid_df.index.values\n",
    "\n",
    "    # Select the labels for the related q_no.\n",
    "    train_labels = labels.loc[labels.q==q_no].set_index('session').loc[train_users]\n",
    "    valid_labels = labels.loc[labels.q==q_no].set_index('session').loc[valid_users]\n",
    "\n",
    "    # Add the label to the filtered datasets.\n",
    "    train_df[\"correct\"] = train_labels[\"correct\"]\n",
    "    valid_df[\"correct\"] = valid_labels[\"correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rows(df, n_flatten=5, only_one=None, drop=None):\n",
    "    \"\"\"\n",
    "    Combines every n_flatten rows of a Pandas DataFrame into a new DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to combine.\n",
    "        n_flatten (int): The number of rows to be combined into a single row.\n",
    "        only_one (list): A list of column names to keep only the first occurrence of in the output DataFrame.\n",
    "        drop (list): A list of column names to drop from the input DataFrame before performing the calculation.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame containing one row for every n_flatten rows of the input DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "    \"\"\"\n",
    "    # Create a copy of the input DataFrame to modify\n",
    "    df = df.copy()\n",
    "\n",
    "    # Use value_counts() to get the count of each session_id\n",
    "    counts = df['session_id'].value_counts()\n",
    "\n",
    "    # Check if each group has the same number of rows\n",
    "    if (counts % n_flatten).any():\n",
    "        # Get the session_ids that need to be generated\n",
    "        need_generating = counts[counts < n_flatten].index.tolist()\n",
    "        num_generated_rows = 0\n",
    "        \n",
    "        # Loop through the session_ids that need to be generated\n",
    "        for session_id in need_generating:\n",
    "            # Generate a new row for this session_id\n",
    "            new_row = {\"session_id\": session_id}\n",
    "            for col in df.columns:\n",
    "                if col == \"session_id\":\n",
    "                    continue\n",
    "                elif df[col].dtype.name == \"category\":\n",
    "                    # Categorical column - set value to \"generated\"\n",
    "                    new_row[col] = \"generated\"\n",
    "                else:\n",
    "                    # Numeric column - set value to average of other values in column with the same level\n",
    "                    level_values = df.loc[df[\"session_id\"] == session_id, \"level\"].unique()\n",
    "                    for level in level_values:\n",
    "                        if level == \"generated\":\n",
    "                            continue\n",
    "                        other_values = df.loc[(df[\"session_id\"] == session_id) & (df[\"level\"] == level), col]\n",
    "                        if other_values.dtype.kind in 'biufc':\n",
    "                            new_value = other_values.mean()\n",
    "                            new_row[col] = new_value\n",
    "                            break\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            num_generated_rows += 1\n",
    "\n",
    "        print(f\"Generated {num_generated_rows} rows with indices: {list(range(len(df) - num_generated_rows, len(df)))}\\n{new_row}\")\n",
    "\n",
    "\n",
    "    # Drop specified columns from input DataFrame\n",
    "    if drop:\n",
    "        df = df.drop(columns=drop)\n",
    "\n",
    "    # Determine the number of rows and columns in the input DataFrame\n",
    "    num_rows, num_cols = df.shape\n",
    "\n",
    "    # Determine the number of new rows in the output DataFrame\n",
    "    num_new_rows = num_rows // n_flatten\n",
    "\n",
    "    # Reshape the flattened values into a new array with the desired shape\n",
    "    values = df.values.flatten()\n",
    "    new_values = values.reshape(num_new_rows, n_flatten*num_cols)\n",
    "\n",
    "    # Create a new DataFrame from the reshaped values\n",
    "    new_df = pd.DataFrame(new_values, columns=[f\"{col}_{i}\" for i in range(1, n_flatten+1) for col in df.columns])\n",
    "\n",
    "    # Drop specified columns from output DataFrame\n",
    "    if only_one:\n",
    "        for col in only_one:\n",
    "            keep_col = f\"{col}_1\"\n",
    "            drop_cols = [f\"{col}_{i}\" for i in range(2, n_flatten+1)]\n",
    "            new_df = new_df.drop(columns=drop_cols)\n",
    "\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "new_df = combine_rows( df_13_22 ,n_flatten= 10 ,drop= [\"level\"], only_one= [\"level_group\",\"music\", \"hq\", \"fullscreen\"])\n",
    "#print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13_22 = pd.read_csv(\"data\\processed\\df_13_22.csv\", index_col= 0, nrows= 20000)\n",
    "df_13_22 = df_13_22.reset_index(drop=True)\n",
    "ex = [\"level_group\",\"music\", \"hq\", \"fullscreen\"]\n",
    "drop = [\"level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combine_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_13_22 \u001b[39m=\u001b[39m combine_rows(df_13_22,n_flatten\u001b[39m=\u001b[39m \u001b[39m10\u001b[39m ,drop\u001b[39m=\u001b[39m drop, only_one\u001b[39m=\u001b[39m ex)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combine_rows' is not defined"
     ]
    }
   ],
   "source": [
    "df_13_22 = combine_rows(df_13_22,n_flatten= 10 ,drop= drop, only_one= ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rows(df, n_flatten=5, only_one=None, drop=None):\n",
    "    \"\"\"\n",
    "    Combines every n_flatten rows of a Pandas DataFrame into a new DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to combine.\n",
    "        n_flatten (int): The number of rows to be combined into a single row.\n",
    "        only_one (list): A list of column names to keep only the first occurrence of in the output DataFrame.\n",
    "        drop (list): A list of column names to drop from the input DataFrame before performing the calculation.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame containing one row for every n_flatten rows of the input DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "    \"\"\"\n",
    "    # Create a copy of the input DataFrame to modify\n",
    "    df = df.copy()\n",
    "\n",
    "    # Use value_counts() to get the count of each session_id\n",
    "    counts = df['session_id'].value_counts()\n",
    "\n",
    "    # Check if each group has the same number of rows\n",
    "    if (counts % n_flatten).any():\n",
    "        # Get the session_ids that need to be generated\n",
    "        need_generating = counts[counts < n_flatten].index.tolist()\n",
    "        num_generated_rows = 0\n",
    "        \n",
    "        # Loop through the session_ids that need to be generated\n",
    "        for session_id in need_generating:\n",
    "            # Generate new rows for this session_id\n",
    "            num_missing_rows = n_flatten - counts[session_id]\n",
    "            new_rows = []\n",
    "            for i in range(num_missing_rows):\n",
    "                new_row = {\"session_id\": session_id}\n",
    "                for col in df.columns:\n",
    "                    if col == \"session_id\":\n",
    "                        continue\n",
    "                    elif df[col].dtype.name == \"category\":\n",
    "                        # Categorical column - set value to \"generated\"\n",
    "                        new_row[col] = \"generated\"\n",
    "                    else:\n",
    "                        # Numeric column - set value to average of other values in column with the same level\n",
    "                        level_values = df.loc[df[\"session_id\"] == session_id, \"level\"].unique()\n",
    "                        for level in level_values:\n",
    "                            if level == \"generated\":\n",
    "                                continue\n",
    "                            other_values = df.loc[(df[\"session_id\"] == session_id) & (df[\"level\"] == level), col]\n",
    "                            if other_values.dtype.kind in 'biufc':\n",
    "                                new_value = other_values.mean()\n",
    "                                new_row[col] = new_value\n",
    "                                break\n",
    "                new_rows.append(new_row)\n",
    "            df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "            num_generated_rows += num_missing_rows\n",
    "\n",
    "        print(f\"Generated {num_generated_rows} rows with indices: {list(range(len(df) - num_generated_rows, len(df)))}\\n{new_rows}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Drop specified columns from input DataFrame\n",
    "    if drop:\n",
    "        df = df.drop(columns=drop)\n",
    "\n",
    "    # Determine the number of rows and columns in the input DataFrame\n",
    "    num_rows, num_cols = df.shape\n",
    "\n",
    "    # Determine the number of new rows in the output DataFrame\n",
    "    num_new_rows = (num_rows + num_generated_rows) // n_flatten\n",
    "\n",
    "    # Reshape the flattened values into a new array with the desired shape\n",
    "    values = df.values.flatten()\n",
    "    new_values = values.reshape(num_new_rows, n_flatten*num_cols)\n",
    "\n",
    "    # Create a new DataFrame from the reshaped values\n",
    "    new_df = pd.DataFrame(new_values, columns=[f\"{col}_{i}\" for i in range(1, n_flatten+1) for col in df.columns])\n",
    "\n",
    "    # Drop specified columns from output DataFrame\n",
    "    if only_one:\n",
    "        for col in only_one:\n",
    "            keep_col = f\"{col}_1\"\n",
    "            drop_cols = [f\"{col}_{i}\" for i in range(2, n_flatten+1)]\n",
    "            new_df = new_df.drop(columns=drop_cols)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rows(df: pd.DataFrame, n_flatten: int) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    # Use value_counts() to get the count of each session_id\n",
    "    counts = df['session_id'].value_counts()\n",
    "\n",
    "    # Check if each group has the same number of rows\n",
    "    if (counts % n_flatten).any():\n",
    "        # Get the session_ids that need to be generated\n",
    "        need_generating = counts[counts < n_flatten].index.tolist()\n",
    "        num_generated_rows = 0\n",
    "        generated_sessions = []\n",
    "        generated_rows = []\n",
    "        \n",
    "        # Loop through the session_ids that need to be generated\n",
    "        for session_id in need_generating:\n",
    "            # Check if all levels are present in this session\n",
    "            levels_present = set(df.loc[df['session_id'] == session_id, 'level'].unique())\n",
    "            min_level = df['level'].min()\n",
    "            max_level = df['level'].max()\n",
    "            expected_levels = set(range(min_level, max_level + 1))\n",
    "            if levels_present != expected_levels:\n",
    "                # Generate new rows for missing levels\n",
    "                missing_levels = expected_levels - levels_present\n",
    "                new_rows = []\n",
    "                for missing_level in missing_levels:\n",
    "                    new_row = {\"session_id\": session_id, \"level\": missing_level}\n",
    "                    for col in df.columns:\n",
    "                        if col == \"session_id\" or col == \"level\":\n",
    "                            continue\n",
    "                        elif df[col].dtype.name == \"category\":\n",
    "                            # Categorical column - set value to \"generated\"\n",
    "                            new_row[col] = \"generated\"\n",
    "                        else:\n",
    "                            # Numeric column - set value to average of other values in column with the same level\n",
    "                            other_values = df.loc[(df[\"session_id\"] == session_id) & (df[\"level\"] == missing_level), col]\n",
    "                            if other_values.dtype.kind in 'biufc':\n",
    "                                new_value = other_values.mean()\n",
    "                                if np.isnan(new_value):\n",
    "                                    new_value = df.loc[df[\"level\"] == missing_level, col].mean()\n",
    "                                new_row[col] = new_value\n",
    "                    new_rows.append(new_row)\n",
    "\n",
    "                # Add the new rows to the dataframe\n",
    "                df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "                num_generated_rows += len(new_rows)\n",
    "                generated_sessions.append({\"session_id\": session_id, \"num_rows\": len(new_rows)})\n",
    "                generated_rows.extend(new_rows)\n",
    "\n",
    "        print(f\"Generated {num_generated_rows} rows with indices: {list(range(len(df) - num_generated_rows, len(df)))}\")\n",
    "        \n",
    "        # Create output dataframe 2\n",
    "        df2 = pd.DataFrame(generated_sessions)\n",
    "        df2 = df2.set_index(\"session_id\")\n",
    "        print(\"Generated rows per session id:\")\n",
    "        print(df2)\n",
    "        \n",
    "        # Create output dataframe 3\n",
    "        df3 = pd.DataFrame(generated_rows)\n",
    "        df3 = df3.reindex(df.columns, axis=1)\n",
    "        print(\"Generated rows:\")\n",
    "        print(df3)\n",
    "    else: \n",
    "        df2 = []\n",
    "        df3 = []\n",
    "    return df, df2, df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 50 rows with indices: [20000, 20001, 20002, 20003, 20004, 20005, 20006, 20007, 20008, 20009, 20010, 20011, 20012, 20013, 20014, 20015, 20016, 20017, 20018, 20019, 20020, 20021, 20022, 20023, 20024, 20025, 20026, 20027, 20028, 20029, 20030, 20031, 20032, 20033, 20034, 20035, 20036, 20037, 20038, 20039, 20040, 20041, 20042, 20043, 20044, 20045, 20046, 20047, 20048, 20049]\n",
      "Generated rows per session id:\n",
      "                   num_rows\n",
      "session_id                 \n",
      "20090316190523732         1\n",
      "20100214275616070         1\n",
      "20100007445515820         1\n",
      "20100411153285710         1\n",
      "20100311385101428         1\n",
      "20110210321880150         1\n",
      "20110212420906190         1\n",
      "20100312152757270         1\n",
      "20110012235136684         1\n",
      "20100118090535520         1\n",
      "20110212174595004         1\n",
      "20110010322671296         1\n",
      "20110209130717610         1\n",
      "20100116202427100         1\n",
      "20100620261406990         1\n",
      "20100319593860984         1\n",
      "20110209485141690         1\n",
      "20100318480867690         1\n",
      "20100115142089760         1\n",
      "20100318174525144         1\n",
      "20100115005512812         1\n",
      "20100523474474980         1\n",
      "20110210180909070         1\n",
      "20100510014844344         1\n",
      "20100110093663916         1\n",
      "20100310430520250         1\n",
      "20100020122406090         1\n",
      "20100510025822616         1\n",
      "20110215162449400         1\n",
      "20100014211946468         1\n",
      "20100211432649536         1\n",
      "20100413494435240         1\n",
      "20100018421509572         1\n",
      "20100211121053492         1\n",
      "20110116152879256         1\n",
      "20100513033741570         1\n",
      "20100210135106010         1\n",
      "20110213450098724         1\n",
      "20100209423871468         1\n",
      "20100309472366890         1\n",
      "20100512192183730         1\n",
      "20100310052382190         1\n",
      "20100310085206010         1\n",
      "20100610533703468         1\n",
      "20100415143631610         2\n",
      "20110219234738916         4\n",
      "Generated rows:\n",
      "           session_id  level  level_group  event_name      name       fqid  \\\n",
      "0   20090316190523732     15          NaN    5.997963  3.393075   9.706721   \n",
      "1   20100214275616070     15          NaN    5.997963  3.393075   9.706721   \n",
      "2   20100007445515820     15          NaN    5.997963  3.393075   9.706721   \n",
      "3   20100411153285710     15          NaN    5.997963  3.393075   9.706721   \n",
      "4   20100311385101428     15          NaN    5.997963  3.393075   9.706721   \n",
      "5   20110210321880150     15          NaN    5.997963  3.393075   9.706721   \n",
      "6   20110212420906190     15          NaN    5.997963  3.393075   9.706721   \n",
      "7   20100312152757270     15          NaN    5.997963  3.393075   9.706721   \n",
      "8   20110012235136684     15          NaN    5.997963  3.393075   9.706721   \n",
      "9   20100118090535520     15          NaN    5.997963  3.393075   9.706721   \n",
      "10  20110212174595004     15          NaN    5.997963  3.393075   9.706721   \n",
      "11  20110010322671296     15          NaN    5.997963  3.393075   9.706721   \n",
      "12  20110209130717610     15          NaN    5.997963  3.393075   9.706721   \n",
      "13  20100116202427100     15          NaN    5.997963  3.393075   9.706721   \n",
      "14  20100620261406990     15          NaN    5.997963  3.393075   9.706721   \n",
      "15  20100319593860984     15          NaN    5.997963  3.393075   9.706721   \n",
      "16  20110209485141690     15          NaN    5.997963  3.393075   9.706721   \n",
      "17  20100318480867690     15          NaN    5.997963  3.393075   9.706721   \n",
      "18  20100115142089760     15          NaN    5.997963  3.393075   9.706721   \n",
      "19  20100318174525144     15          NaN    5.997963  3.393075   9.706721   \n",
      "20  20100115005512812     15          NaN    5.997963  3.393075   9.706721   \n",
      "21  20100523474474980     15          NaN    5.997963  3.393075   9.706721   \n",
      "22  20110210180909070     15          NaN    5.997963  3.393075   9.706721   \n",
      "23  20100510014844344     15          NaN    5.997963  3.393075   9.706721   \n",
      "24  20100110093663916     20          NaN    7.183500  3.322500  12.729000   \n",
      "25  20100310430520250     15          NaN    5.997963  3.393075   9.706721   \n",
      "26  20100020122406090     20          NaN    7.183500  3.322500  12.729000   \n",
      "27  20100510025822616     15          NaN    5.997963  3.393075   9.706721   \n",
      "28  20110215162449400     15          NaN    5.997963  3.393075   9.706721   \n",
      "29  20100014211946468     15          NaN    5.997963  3.393075   9.706721   \n",
      "30  20100211432649536     15          NaN    5.997963  3.393075   9.706721   \n",
      "31  20100413494435240     15          NaN    5.997963  3.393075   9.706721   \n",
      "32  20100018421509572     15          NaN    5.997963  3.393075   9.706721   \n",
      "33  20100211121053492     15          NaN    5.997963  3.393075   9.706721   \n",
      "34  20110116152879256     15          NaN    5.997963  3.393075   9.706721   \n",
      "35  20100513033741570     15          NaN    5.997963  3.393075   9.706721   \n",
      "36  20100210135106010     15          NaN    5.997963  3.393075   9.706721   \n",
      "37  20110213450098724     15          NaN    5.997963  3.393075   9.706721   \n",
      "38  20100209423871468     15          NaN    5.997963  3.393075   9.706721   \n",
      "39  20100309472366890     20          NaN    7.183500  3.322500  12.729000   \n",
      "40  20100512192183730     21          NaN    7.471293  3.540689  17.024463   \n",
      "41  20100310052382190     15          NaN    5.997963  3.393075   9.706721   \n",
      "42  20100310085206010     15          NaN    5.997963  3.393075   9.706721   \n",
      "43  20100610533703468     15          NaN    5.997963  3.393075   9.706721   \n",
      "44  20100415143631610     20          NaN    7.183500  3.322500  12.729000   \n",
      "45  20100415143631610     15          NaN    5.997963  3.393075   9.706721   \n",
      "46  20110219234738916     19          NaN    6.701597  3.480040   6.278942   \n",
      "47  20110219234738916     20          NaN    7.183500  3.322500  12.729000   \n",
      "48  20110219234738916     21          NaN    7.471293  3.540689  17.024463   \n",
      "49  20110219234738916     22          NaN    4.381238  2.651198   6.265469   \n",
      "\n",
      "    room_fqid  text_fqid  fullscreen        hq  ...  room_coor_x_std  \\\n",
      "0    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "1    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "2    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "3    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "4    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "5    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "6    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "7    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "8    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "9    5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "10   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "11   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "12   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "13   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "14   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "15   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "16   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "17   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "18   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "19   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "20   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "21   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "22   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "23   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "24   3.412000   2.560000    0.140000  0.127500  ...       305.634194   \n",
      "25   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "26   3.412000   2.560000    0.140000  0.127500  ...       305.634194   \n",
      "27   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "28   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "29   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "30   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "31   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "32   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "33   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "34   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "35   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "36   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "37   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "38   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "39   3.412000   2.560000    0.140000  0.127500  ...       305.634194   \n",
      "40   5.978033   4.613580    0.140290  0.127309  ...       340.735260   \n",
      "41   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "42   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "43   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "44   3.412000   2.560000    0.140000  0.127500  ...       305.634194   \n",
      "45   5.549389   3.574847    0.141548  0.126782  ...       633.858911   \n",
      "46   2.058383   3.800399    0.140220  0.127246  ...       382.323312   \n",
      "47   3.412000   2.560000    0.140000  0.127500  ...       305.634194   \n",
      "48   5.978033   4.613580    0.140290  0.127309  ...       340.735260   \n",
      "49   3.433633   0.160679    0.140220  0.127246  ...       411.933894   \n",
      "\n",
      "    room_coor_y_std  screen_coor_x_std  screen_coor_y_std  hover_duration_std  \\\n",
      "0        181.396420         252.106511         132.631936         1803.215590   \n",
      "1        181.396420         252.106511         132.631936         1803.215590   \n",
      "2        181.396420         252.106511         132.631936         1803.215590   \n",
      "3        181.396420         252.106511         132.631936         1803.215590   \n",
      "4        181.396420         252.106511         132.631936         1803.215590   \n",
      "5        181.396420         252.106511         132.631936         1803.215590   \n",
      "6        181.396420         252.106511         132.631936         1803.215590   \n",
      "7        181.396420         252.106511         132.631936         1803.215590   \n",
      "8        181.396420         252.106511         132.631936         1803.215590   \n",
      "9        181.396420         252.106511         132.631936         1803.215590   \n",
      "10       181.396420         252.106511         132.631936         1803.215590   \n",
      "11       181.396420         252.106511         132.631936         1803.215590   \n",
      "12       181.396420         252.106511         132.631936         1803.215590   \n",
      "13       181.396420         252.106511         132.631936         1803.215590   \n",
      "14       181.396420         252.106511         132.631936         1803.215590   \n",
      "15       181.396420         252.106511         132.631936         1803.215590   \n",
      "16       181.396420         252.106511         132.631936         1803.215590   \n",
      "17       181.396420         252.106511         132.631936         1803.215590   \n",
      "18       181.396420         252.106511         132.631936         1803.215590   \n",
      "19       181.396420         252.106511         132.631936         1803.215590   \n",
      "20       181.396420         252.106511         132.631936         1803.215590   \n",
      "21       181.396420         252.106511         132.631936         1803.215590   \n",
      "22       181.396420         252.106511         132.631936         1803.215590   \n",
      "23       181.396420         252.106511         132.631936         1803.215590   \n",
      "24       157.657595         208.851279         141.154603         6937.029742   \n",
      "25       181.396420         252.106511         132.631936         1803.215590   \n",
      "26       157.657595         208.851279         141.154603         6937.029742   \n",
      "27       181.396420         252.106511         132.631936         1803.215590   \n",
      "28       181.396420         252.106511         132.631936         1803.215590   \n",
      "29       181.396420         252.106511         132.631936         1803.215590   \n",
      "30       181.396420         252.106511         132.631936         1803.215590   \n",
      "31       181.396420         252.106511         132.631936         1803.215590   \n",
      "32       181.396420         252.106511         132.631936         1803.215590   \n",
      "33       181.396420         252.106511         132.631936         1803.215590   \n",
      "34       181.396420         252.106511         132.631936         1803.215590   \n",
      "35       181.396420         252.106511         132.631936         1803.215590   \n",
      "36       181.396420         252.106511         132.631936         1803.215590   \n",
      "37       181.396420         252.106511         132.631936         1803.215590   \n",
      "38       181.396420         252.106511         132.631936         1803.215590   \n",
      "39       157.657595         208.851279         141.154603         6937.029742   \n",
      "40       150.355259         226.349914         130.224918         2395.226285   \n",
      "41       181.396420         252.106511         132.631936         1803.215590   \n",
      "42       181.396420         252.106511         132.631936         1803.215590   \n",
      "43       181.396420         252.106511         132.631936         1803.215590   \n",
      "44       157.657595         208.851279         141.154603         6937.029742   \n",
      "45       181.396420         252.106511         132.631936         1803.215590   \n",
      "46       310.743615         192.809794         140.192997          918.604854   \n",
      "47       157.657595         208.851279         141.154603         6937.029742   \n",
      "48       150.355259         226.349914         130.224918         2395.226285   \n",
      "49       162.695903         242.648482         145.511604          379.963252   \n",
      "\n",
      "    difference_clicks_std  index_sum_of_actions  difference_clicks_max  \\\n",
      "0                5.949074             57.591141              43.285412   \n",
      "1                5.949074             57.591141              43.285412   \n",
      "2                5.949074             57.591141              43.285412   \n",
      "3                5.949074             57.591141              43.285412   \n",
      "4                5.949074             57.591141              43.285412   \n",
      "5                5.949074             57.591141              43.285412   \n",
      "6                5.949074             57.591141              43.285412   \n",
      "7                5.949074             57.591141              43.285412   \n",
      "8                5.949074             57.591141              43.285412   \n",
      "9                5.949074             57.591141              43.285412   \n",
      "10               5.949074             57.591141              43.285412   \n",
      "11               5.949074             57.591141              43.285412   \n",
      "12               5.949074             57.591141              43.285412   \n",
      "13               5.949074             57.591141              43.285412   \n",
      "14               5.949074             57.591141              43.285412   \n",
      "15               5.949074             57.591141              43.285412   \n",
      "16               5.949074             57.591141              43.285412   \n",
      "17               5.949074             57.591141              43.285412   \n",
      "18               5.949074             57.591141              43.285412   \n",
      "19               5.949074             57.591141              43.285412   \n",
      "20               5.949074             57.591141              43.285412   \n",
      "21               5.949074             57.591141              43.285412   \n",
      "22               5.949074             57.591141              43.285412   \n",
      "23               5.949074             57.591141              43.285412   \n",
      "24              24.065911             51.740000             144.559817   \n",
      "25               5.949074             57.591141              43.285412   \n",
      "26              24.065911             51.740000             144.559817   \n",
      "27               5.949074             57.591141              43.285412   \n",
      "28               5.949074             57.591141              43.285412   \n",
      "29               5.949074             57.591141              43.285412   \n",
      "30               5.949074             57.591141              43.285412   \n",
      "31               5.949074             57.591141              43.285412   \n",
      "32               5.949074             57.591141              43.285412   \n",
      "33               5.949074             57.591141              43.285412   \n",
      "34               5.949074             57.591141              43.285412   \n",
      "35               5.949074             57.591141              43.285412   \n",
      "36               5.949074             57.591141              43.285412   \n",
      "37               5.949074             57.591141              43.285412   \n",
      "38               5.949074             57.591141              43.285412   \n",
      "39              24.065911             51.740000             144.559817   \n",
      "40              12.366104             94.129306             137.277377   \n",
      "41               5.949074             57.591141              43.285412   \n",
      "42               5.949074             57.591141              43.285412   \n",
      "43               5.949074             57.591141              43.285412   \n",
      "44              24.065911             51.740000             144.559817   \n",
      "45               5.949074             57.591141              43.285412   \n",
      "46              70.232268             54.434631             408.776123   \n",
      "47              24.065911             51.740000             144.559817   \n",
      "48              12.366104             94.129306             137.277377   \n",
      "49              16.350862             22.113273              99.155663   \n",
      "\n",
      "    elapsed_time_max  clicks_per_second  \n",
      "0         109.705038           0.790943  \n",
      "1         109.705038           0.790943  \n",
      "2         109.705038           0.790943  \n",
      "3         109.705038           0.790943  \n",
      "4         109.705038           0.790943  \n",
      "5         109.705038           0.790943  \n",
      "6         109.705038           0.790943  \n",
      "7         109.705038           0.790943  \n",
      "8         109.705038           0.790943  \n",
      "9         109.705038           0.790943  \n",
      "10        109.705038           0.790943  \n",
      "11        109.705038           0.790943  \n",
      "12        109.705038           0.790943  \n",
      "13        109.705038           0.790943  \n",
      "14        109.705038           0.790943  \n",
      "15        109.705038           0.790943  \n",
      "16        109.705038           0.790943  \n",
      "17        109.705038           0.790943  \n",
      "18        109.705038           0.790943  \n",
      "19        109.705038           0.790943  \n",
      "20        109.705038           0.790943  \n",
      "21        109.705038           0.790943  \n",
      "22        109.705038           0.790943  \n",
      "23        109.705038           0.790943  \n",
      "24        202.075804           0.810066  \n",
      "25        109.705038           0.790943  \n",
      "26        202.075804           0.810066  \n",
      "27        109.705038           0.790943  \n",
      "28        109.705038           0.790943  \n",
      "29        109.705038           0.790943  \n",
      "30        109.705038           0.790943  \n",
      "31        109.705038           0.790943  \n",
      "32        109.705038           0.790943  \n",
      "33        109.705038           0.790943  \n",
      "34        109.705038           0.790943  \n",
      "35        109.705038           0.790943  \n",
      "36        109.705038           0.790943  \n",
      "37        109.705038           0.790943  \n",
      "38        109.705038           0.790943  \n",
      "39        202.075804           0.810066  \n",
      "40        247.358364           0.814173  \n",
      "41        109.705038           0.790943  \n",
      "42        109.705038           0.790943  \n",
      "43        109.705038           0.790943  \n",
      "44        202.075804           0.810066  \n",
      "45        109.705038           0.790943  \n",
      "46        481.332857           0.760698  \n",
      "47        202.075804           0.810066  \n",
      "48        247.358364           0.814173  \n",
      "49        116.351439           0.907462  \n",
      "\n",
      "[50 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df_13_22, generated, rows_df = generate_rows(df_13_22, n_flatten= 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = new_df[\"session_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1,collected,rowss = generate_rows(dataset_df_0_4, n_flatten= 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
