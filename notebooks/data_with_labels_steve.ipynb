{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports for the Data Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import gc\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory:  n:\\MASTER_DS\\Code\\Kaggle_competition\\Kaggle-seminar\\student-performance\n"
     ]
    }
   ],
   "source": [
    "# get working directory and remove last folder\n",
    "# TODO: make this more robust\n",
    "wd = os.path.dirname(os.getcwd())\n",
    "os.chdir(wd)\n",
    "print('Working Directory: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data, differentdatasets\n",
    "dtypes = {\n",
    "    'level': np.uint8,\n",
    "    \"level_group\": \"category\",\n",
    "    'event_name': np.uint8,\n",
    "    'name': np.uint8,\n",
    "    'fqid': np.uint8,\n",
    "    'room_fqid': np.uint8,           \n",
    "    \"text_fqid\": np.uint8,\n",
    "    'fullscreen': np.uint8,\n",
    "    'hq': np.uint8,\n",
    "    'music': np.uint8,\n",
    "    'hover_duration_mean': np.float32,\n",
    "    'difference_clicks_mean': np.float32,\n",
    "    'elapsed_time_std': np.float32,\n",
    "    'page_std': np.float32,\n",
    "    'room_coor_x_std': np.float32,\n",
    "    'room_coor_y_std': np.float32,\n",
    "    'screen_coor_x_std': np.float32,\n",
    "    'screen_coor_y_std': np.float32,\n",
    "    'hover_duration_std': np.float32,\n",
    "    'difference_clicks_std': np.float32,\n",
    "    'index_sum_of_actions': np.float32,\n",
    "    'difference_clicks_max': np.float32,\n",
    "    'elapsed_time_max': np.float32,\n",
    "    'clicks_per_second': np.float32}\n",
    "\n",
    "dataset_df = pd.read_csv(\"data/processed/dataset_df_level.csv\", dtype=dtypes)\n",
    "\n",
    "#load the label dataset\n",
    "#labels = pd.read_csv(\"data/processed/labels.csv\")\n",
    "dataset_df_0_4 = pd.read_csv(\"data/processed/df_0_4.csv\", dtype=dtypes, index_col= 0)\n",
    "dataset_df_0_4 = dataset_df_0_4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test-split\n",
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "    USER_LIST = dataset_df.index.unique()\n",
    "    split = int(len(USER_LIST) * (1 - 0.20))\n",
    "    return dataset.loc[USER_LIST[:split]], dataset.loc[USER_LIST[split:]]\n",
    "\n",
    "train_x, valid_x = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_x), len(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the unique list of user sessions in the validation dataset. We assigned \n",
    "# `session_id` as the index of our feature engineered dataset. Hence fetching \n",
    "# the unique values in the index column will give us a list of users in the \n",
    "# validation set.\n",
    "VALID_USER_LIST = valid_x.index.unique()\n",
    "\n",
    "# Create a dataframe for storing the predictions of each question for all users\n",
    "# in the validation set.\n",
    "# For this, the required size of the data frame is: \n",
    "# (no: of users in validation set  x no of questions).\n",
    "# We will initialize all the predicted values in the data frame to zero.\n",
    "# The dataframe's index column is the user `session_id`s. \n",
    "prediction_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
    "\n",
    "# Create an empty dictionary to store the models created for each question.\n",
    "models = {}\n",
    "\n",
    "# Create an empty dictionary to store the evaluation score for each question.\n",
    "evaluation_dict ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get labels and data together\n",
    "# Iterate through questions 1 to 18 to train models for each question, evaluate\n",
    "# the trained model and store the predicted values.\n",
    "for q_no in range(1,19):\n",
    "\n",
    "    # Select level group for the question based on the q_no.\n",
    "    if q_no<=3: grp = '0-4'\n",
    "    elif q_no<=13: grp = '5-12'\n",
    "    elif q_no<=22: grp = '13-22'\n",
    "    print(\"### q_no\", q_no, \"grp\", grp)\n",
    "    \n",
    "        \n",
    "    # Filter the rows in the datasets based on the selected level group. \n",
    "    train_df = train_x.loc[train_x.level_group == grp]\n",
    "    train_users = train_df.index.values\n",
    "    valid_df = valid_x.loc[valid_x.level_group == grp]\n",
    "    valid_users = valid_df.index.values\n",
    "\n",
    "    # Select the labels for the related q_no.\n",
    "    train_labels = labels.loc[labels.q==q_no].set_index('session').loc[train_users]\n",
    "    valid_labels = labels.loc[labels.q==q_no].set_index('session').loc[valid_users]\n",
    "\n",
    "    # Add the label to the filtered datasets.\n",
    "    train_df[\"correct\"] = train_labels[\"correct\"]\n",
    "    valid_df[\"correct\"] = valid_labels[\"correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outdated\n",
    "'''def combine_rows(df, n_flatten=5, only_one=None, drop=None):\n",
    "    \"\"\"\n",
    "    Combines every n_flatten rows of a Pandas DataFrame into a new DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to combine.\n",
    "        n_flatten (int): The number of rows to be combined into a single row.\n",
    "        only_one (list): A list of column names to keep only the first occurrence of in the output DataFrame.\n",
    "        drop (list): A list of column names to drop from the input DataFrame before performing the calculation.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame containing one row for every n_flatten rows of the input DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "    \"\"\"\n",
    "    # Create a copy of the input DataFrame to modify\n",
    "    df = df.copy()\n",
    "\n",
    "    # Use value_counts() to get the count of each session_id\n",
    "    counts = df['session_id'].value_counts()\n",
    "\n",
    "    # Check if each group has the same number of rows\n",
    "    if (counts % n_flatten).any():\n",
    "        # Get the session_ids that need to be generated\n",
    "        need_generating = counts[counts < n_flatten].index.tolist()\n",
    "        num_generated_rows = 0\n",
    "        \n",
    "        # Loop through the session_ids that need to be generated\n",
    "        for session_id in need_generating:\n",
    "            # Generate a new row for this session_id\n",
    "            new_row = {\"session_id\": session_id}\n",
    "            for col in df.columns:\n",
    "                if col == \"session_id\":\n",
    "                    continue\n",
    "                elif df[col].dtype.name == \"category\":\n",
    "                    # Categorical column - set value to \"generated\"\n",
    "                    new_row[col] = \"generated\"\n",
    "                else:\n",
    "                    # Numeric column - set value to average of other values in column with the same level\n",
    "                    level_values = df.loc[df[\"session_id\"] == session_id, \"level\"].unique()\n",
    "                    for level in level_values:\n",
    "                        if level == \"generated\":\n",
    "                            continue\n",
    "                        other_values = df.loc[(df[\"session_id\"] == session_id) & (df[\"level\"] == level), col]\n",
    "                        if other_values.dtype.kind in 'biufc':\n",
    "                            new_value = other_values.mean()\n",
    "                            new_row[col] = new_value\n",
    "                            break\n",
    "            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            num_generated_rows += 1\n",
    "\n",
    "        print(f\"Generated {num_generated_rows} rows with indices: {list(range(len(df) - num_generated_rows, len(df)))}\\n{new_row}\")\n",
    "\n",
    "\n",
    "    # Drop specified columns from input DataFrame\n",
    "    if drop:\n",
    "        df = df.drop(columns=drop)\n",
    "\n",
    "    # Determine the number of rows and columns in the input DataFrame\n",
    "    num_rows, num_cols = df.shape\n",
    "\n",
    "    # Determine the number of new rows in the output DataFrame\n",
    "    num_new_rows = num_rows // n_flatten\n",
    "\n",
    "    # Reshape the flattened values into a new array with the desired shape\n",
    "    values = df.values.flatten()\n",
    "    new_values = values.reshape(num_new_rows, n_flatten*num_cols)\n",
    "\n",
    "    # Create a new DataFrame from the reshaped values\n",
    "    new_df = pd.DataFrame(new_values, columns=[f\"{col}_{i}\" for i in range(1, n_flatten+1) for col in df.columns])\n",
    "\n",
    "    # Drop specified columns from output DataFrame\n",
    "    if only_one:\n",
    "        for col in only_one:\n",
    "            keep_col = f\"{col}_1\"\n",
    "            drop_cols = [f\"{col}_{i}\" for i in range(2, n_flatten+1)]\n",
    "            new_df = new_df.drop(columns=drop_cols)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "new_df = combine_rows(df_13_22 ,n_flatten= 10 ,drop= [\"level\"], only_one= [\"level_group\",\"music\", \"hq\", \"fullscreen\"])\n",
    "#print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data for test purporses\n",
    "df_13_22 = pd.read_csv(\"data\\processed\\df_13_22.csv\", index_col= 0, nrows= 200000, dtype= dtypes)\n",
    "df_13_22 = df_13_22.reset_index(drop=True)\n",
    "ex = [\"level_group\",\"music\", \"hq\", \"fullscreen\"]\n",
    "drop = [\"level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_13_22 = combine_rows(df_13_22,n_flatten= 10 ,drop= drop, only_one= ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def combine_rows(df, n_flatten=5, only_one=None, drop=None):\\n    \"\"\"\\n    Combines every n_flatten rows of a Pandas DataFrame into a new DataFrame, with each row containing the combined values from the n_flatten rows.\\n\\n    Args:\\n        df (pandas.DataFrame): The DataFrame to combine.\\n        n_flatten (int): The number of rows to be combined into a single row.\\n        only_one (list): A list of column names to keep only the first occurrence of in the output DataFrame.\\n        drop (list): A list of column names to drop from the input DataFrame before performing the calculation.\\n\\n    Returns:\\n        pandas.DataFrame: A new DataFrame containing one row for every n_flatten rows of the input DataFrame, with each row containing the combined values from the n_flatten rows.\\n    \"\"\"\\n    # Create a copy of the input DataFrame to modify\\n    df = df.copy()\\n\\n    # Use value_counts() to get the count of each session_id\\n    counts = df[\\'session_id\\'].value_counts()\\n\\n    # Check if each group has the same number of rows\\n    if (counts % n_flatten).any():\\n        # Get the session_ids that need to be generated\\n        need_generating = counts[counts < n_flatten].index.tolist()\\n        num_generated_rows = 0\\n        \\n        # Loop through the session_ids that need to be generated\\n        for session_id in need_generating:\\n            # Generate new rows for this session_id\\n            num_missing_rows = n_flatten - counts[session_id]\\n            new_rows = []\\n            for i in range(num_missing_rows):\\n                new_row = {\"session_id\": session_id}\\n                for col in df.columns:\\n                    if col == \"session_id\":\\n                        continue\\n                    elif df[col].dtype.name == \"category\":\\n                        # Categorical column - set value to \"generated\"\\n                        new_row[col] = \"generated\"\\n                    else:\\n                        # Numeric column - set value to average of other values in column with the same level\\n                        level_values = df.loc[df[\"session_id\"] == session_id, \"level\"].unique()\\n                        for level in level_values:\\n                            if level == \"generated\":\\n                                continue\\n                            other_values = df.loc[(df[\"session_id\"] == session_id) & (df[\"level\"] == level), col]\\n                            if other_values.dtype.kind in \\'biufc\\':\\n                                new_value = other_values.mean()\\n                                new_row[col] = new_value\\n                                break\\n                new_rows.append(new_row)\\n            df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\\n            num_generated_rows += num_missing_rows\\n\\n        print(f\"Generated {num_generated_rows} rows with indices: {list(range(len(df) - num_generated_rows, len(df)))}\\n{new_rows}\")\\n\\n\\n\\n\\n    # Drop specified columns from input DataFrame\\n    if drop:\\n        df = df.drop(columns=drop)\\n\\n    # Determine the number of rows and columns in the input DataFrame\\n    num_rows, num_cols = df.shape\\n\\n    # Determine the number of new rows in the output DataFrame\\n    num_new_rows = (num_rows + num_generated_rows) // n_flatten\\n\\n    # Reshape the flattened values into a new array with the desired shape\\n    values = df.values.flatten()\\n    new_values = values.reshape(num_new_rows, n_flatten*num_cols)\\n\\n    # Create a new DataFrame from the reshaped values\\n    new_df = pd.DataFrame(new_values, columns=[f\"{col}_{i}\" for i in range(1, n_flatten+1) for col in df.columns])\\n\\n    # Drop specified columns from output DataFrame\\n    if only_one:\\n        for col in only_one:\\n            keep_col = f\"{col}_1\"\\n            drop_cols = [f\"{col}_{i}\" for i in range(2, n_flatten+1)]\\n            new_df = new_df.drop(columns=drop_cols)\\n\\n    return new_df'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outdated\n",
    "'''def combine_rows(df, n_flatten=5, only_one=None, drop=None):\n",
    "    \"\"\"\n",
    "    Combines every n_flatten rows of a Pandas DataFrame into a new DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to combine.\n",
    "        n_flatten (int): The number of rows to be combined into a single row.\n",
    "        only_one (list): A list of column names to keep only the first occurrence of in the output DataFrame.\n",
    "        drop (list): A list of column names to drop from the input DataFrame before performing the calculation.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame containing one row for every n_flatten rows of the input DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "    \"\"\"\n",
    "    # Create a copy of the input DataFrame to modify\n",
    "    df = df.copy()\n",
    "\n",
    "    # Use value_counts() to get the count of each session_id\n",
    "    counts = df['session_id'].value_counts()\n",
    "\n",
    "    # Check if each group has the same number of rows\n",
    "    if (counts % n_flatten).any():\n",
    "        # Get the session_ids that need to be generated\n",
    "        need_generating = counts[counts < n_flatten].index.tolist()\n",
    "        num_generated_rows = 0\n",
    "        \n",
    "        # Loop through the session_ids that need to be generated\n",
    "        for session_id in need_generating:\n",
    "            # Generate new rows for this session_id\n",
    "            num_missing_rows = n_flatten - counts[session_id]\n",
    "            new_rows = []\n",
    "            for i in range(num_missing_rows):\n",
    "                new_row = {\"session_id\": session_id}\n",
    "                for col in df.columns:\n",
    "                    if col == \"session_id\":\n",
    "                        continue\n",
    "                    elif df[col].dtype.name == \"category\":\n",
    "                        # Categorical column - set value to \"generated\"\n",
    "                        new_row[col] = \"generated\"\n",
    "                    else:\n",
    "                        # Numeric column - set value to average of other values in column with the same level\n",
    "                        level_values = df.loc[df[\"session_id\"] == session_id, \"level\"].unique()\n",
    "                        for level in level_values:\n",
    "                            if level == \"generated\":\n",
    "                                continue\n",
    "                            other_values = df.loc[(df[\"session_id\"] == session_id) & (df[\"level\"] == level), col]\n",
    "                            if other_values.dtype.kind in 'biufc':\n",
    "                                new_value = other_values.mean()\n",
    "                                new_row[col] = new_value\n",
    "                                break\n",
    "                new_rows.append(new_row)\n",
    "            df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "            num_generated_rows += num_missing_rows\n",
    "\n",
    "        print(f\"Generated {num_generated_rows} rows with indices: {list(range(len(df) - num_generated_rows, len(df)))}\\n{new_rows}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Drop specified columns from input DataFrame\n",
    "    if drop:\n",
    "        df = df.drop(columns=drop)\n",
    "\n",
    "    # Determine the number of rows and columns in the input DataFrame\n",
    "    num_rows, num_cols = df.shape\n",
    "\n",
    "    # Determine the number of new rows in the output DataFrame\n",
    "    num_new_rows = (num_rows + num_generated_rows) // n_flatten\n",
    "\n",
    "    # Reshape the flattened values into a new array with the desired shape\n",
    "    values = df.values.flatten()\n",
    "    new_values = values.reshape(num_new_rows, n_flatten*num_cols)\n",
    "\n",
    "    # Create a new DataFrame from the reshaped values\n",
    "    new_df = pd.DataFrame(new_values, columns=[f\"{col}_{i}\" for i in range(1, n_flatten+1) for col in df.columns])\n",
    "\n",
    "    # Drop specified columns from output DataFrame\n",
    "    if only_one:\n",
    "        for col in only_one:\n",
    "            keep_col = f\"{col}_1\"\n",
    "            drop_cols = [f\"{col}_{i}\" for i in range(2, n_flatten+1)]\n",
    "            new_df = new_df.drop(columns=drop_cols)\n",
    "\n",
    "    return new_df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rows(df: pd.DataFrame, n_flatten: int, level_g: str):\n",
    "    # Use value_counts() to get the count of each session_id\n",
    "    counts = df['session_id'].value_counts()\n",
    "\n",
    "    # Check if each group has the same number of rows\n",
    "    if (counts % n_flatten).any():\n",
    "        # Get the session_ids that need to be generated\n",
    "        need_generating = counts[counts < n_flatten].index.tolist()\n",
    "        num_generated_rows = 0\n",
    "        generated_sessions = []\n",
    "        generated_rows = []\n",
    "\n",
    "        # Loop through the session_ids that need to be generated\n",
    "        for session_id in need_generating:\n",
    "            # Check if all levels are present in this session\n",
    "            levels_present = set(df.loc[df['session_id'] == session_id, 'level'].unique())\n",
    "            min_level = df['level'].min()\n",
    "            max_level = df['level'].max()\n",
    "            expected_levels = set(range(min_level, max_level + 1))\n",
    "            if levels_present != expected_levels:\n",
    "                # Generate new rows for missing levels\n",
    "                missing_levels = expected_levels - levels_present\n",
    "                new_rows = []\n",
    "                for missing_level in missing_levels:\n",
    "                    new_row = {\"session_id\": session_id, \"level\": missing_level}\n",
    "                    for col in df.columns:\n",
    "                        if col == \"session_id\" or col == \"level\":\n",
    "                            continue\n",
    "                        \n",
    "                        else:\n",
    "                            # Numeric column - set value to average of other values in column with the same level\n",
    "                            other_values = df.loc[(df[\"session_id\"] == session_id) & (df[\"level\"] == missing_level), col]\n",
    "                            if other_values.dtype.kind in 'biufc':\n",
    "                                new_value = other_values.mean()\n",
    "                                if np.isnan(new_value):\n",
    "                                    new_value = df.loc[df[\"level\"] == missing_level, col].mean()\n",
    "                                new_row[col] = new_value\n",
    "                    new_rows.append(new_row)\n",
    "\n",
    "                # Add the new rows to the dataframe\n",
    "                df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "                num_generated_rows += len(new_rows)\n",
    "                generated_sessions.append({\"session_id\": session_id, \"num_rows\": len(new_rows)})\n",
    "                generated_rows.extend(new_rows)\n",
    "\n",
    "        print(f\"Generated {num_generated_rows} rows with indices: {list(range(len(df) - num_generated_rows, len(df)))}\")\n",
    "\n",
    "        # Create output dataframe 2\n",
    "        df2 = pd.DataFrame(generated_sessions)\n",
    "        df2 = df2.set_index(\"session_id\")\n",
    "        print(\"Generated rows per session id:\")\n",
    "        print(df2)\n",
    "\n",
    "        # Create output dataframe 3\n",
    "        df3 = pd.DataFrame(generated_rows)\n",
    "        df3 = df3.reindex(df.columns, axis=1)\n",
    "        print(\"Generated rows:\")\n",
    "        print(df3)\n",
    "    else:\n",
    "        df2 = pd.DataFrame()\n",
    "        df3 = pd.DataFrame()\n",
    "    df[\"level_group\"] = level_g\n",
    "    df3[\"level_group\"] = level_g\n",
    "    return df, df2, df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rows(df, n_flatten=5, only_one=None, drop=None):\n",
    "    \"\"\"\n",
    "    Combines every n_flatten rows of a Pandas DataFrame into a new DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to combine.\n",
    "        n_flatten (int): The number of rows to be combined into a single row.\n",
    "        only_one (list): A list of column names to keep only the first occurrence of in the output DataFrame.\n",
    "        drop (list): A list of column names to drop from the input DataFrame before performing the calculation.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame containing one row for every n_flatten rows of the input DataFrame, with each row containing the combined values from the n_flatten rows.\n",
    "    \"\"\"\n",
    "    # Create a copy of the input DataFrame to modify\n",
    "    df = df.copy()\n",
    "\n",
    "    # Drop specified columns from input DataFrame\n",
    "    if drop:\n",
    "        df = df.drop(columns=drop)\n",
    "\n",
    "    # Check if all session_id's occur the same amount of times\n",
    "    session_counts = df['session_id'].value_counts()\n",
    "    if len(set(session_counts.values)) > 1:\n",
    "        raise ValueError(\"Missing level: All session_id's should occur the same amount of times.\")\n",
    "\n",
    "    # Determine the number of rows and columns in the input DataFrame\n",
    "    num_rows, num_cols = df.shape\n",
    "\n",
    "    # Determine the number of new rows in the output DataFrame\n",
    "    num_new_rows = num_rows // n_flatten\n",
    "\n",
    "    # Reshape the flattened values into a new array with the desired shape\n",
    "    values = df.values.flatten()\n",
    "    new_values = values.reshape(num_new_rows, n_flatten*num_cols)\n",
    "\n",
    "    # Create a new DataFrame from the reshaped values\n",
    "    new_df = pd.DataFrame(new_values, columns=[f\"{col}_{i}\" for i in range(1, n_flatten+1) for col in df.columns])\n",
    "\n",
    "    # Drop specified columns from output DataFrame\n",
    "    if only_one:\n",
    "        for col in only_one:\n",
    "            keep_col = f\"{col}_1\"\n",
    "            drop_cols = [f\"{col}_{i}\" for i in range(2, n_flatten+1)]\n",
    "            new_df = new_df.drop(columns=drop_cols)\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['13-22'], ordered=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_13_22[\"level_group\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_4_gen, generated, rows_df = generate_rows(dataset_df_0_4, n_flatten= 5, level_g = \"0-4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
