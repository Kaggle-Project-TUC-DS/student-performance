{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports for the Data Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory:  n:\\MASTER_DS\\Code\\Kaggle_competition\\Kaggle-seminar\\student-performance\n"
     ]
    }
   ],
   "source": [
    "# get working directory and remove last folder\n",
    "# TODO: make this more robust\n",
    "wd = os.path.dirname(os.getcwd())\n",
    "os.chdir(wd)\n",
    "print('Working Directory: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes={\n",
    "    'elapsed_time':np.int32,\n",
    "    'event_name':'category',\n",
    "    'name':'category',\n",
    "    'level':np.uint8,\n",
    "    'room_coor_x':np.float32,\n",
    "    'index':np.int32,\n",
    "    'room_coor_y':np.float32,\n",
    "    'screen_coor_x':np.float32,\n",
    "    'screen_coor_y':np.float32,\n",
    "    'hover_duration':np.float32,\n",
    "    'text':'category',\n",
    "    'fqid':'category',\n",
    "    'room_fqid':'category',\n",
    "    'text_fqid':'category',\n",
    "    'fullscreen':'category',\n",
    "    'hq':'category',\n",
    "    'music':'category',\n",
    "    'level_group':'category'}\n",
    "\n",
    "\n",
    "# os.chdir('N:\\MASTER_DS\\Code\\Kaggle_competition\\Kaggle-seminar\\student-performance')\n",
    "dataset_df = pd.read_csv('data/raw/train.csv', dtype=dtypes, nrows= 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing function to add variables and rescale the time \n",
    "def adding_new_variables_rescaling(dataset_df):\n",
    "    dataset_df = dataset_df.sort_values(['session_id','elapsed_time'])\n",
    "    dataset_df['elapsed_time'] = dataset_df['elapsed_time']/1000\n",
    "    group = dataset_df.groupby(['session_id','level'])['elapsed_time'].diff()\n",
    "    group = group.fillna(value= 0)\n",
    "    dataset_df= dataset_df.assign(difference_clicks = group)\n",
    "\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing to combine variables on level stage\n",
    "#Function to clean the sequential data for the training of the model\n",
    "\n",
    "#For that Function to work we need to specify the variables in Categorical and Numerical & Counting\n",
    "\n",
    "CATEGORICAL = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid', 'fullscreen', 'hq', 'music']\n",
    "NUMERICALmean = ['hover_duration','difference_clicks']\n",
    "NUMERICALstd = ['elapsed_time','page','room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration', 'difference_clicks']\n",
    "COUNTING = ['index']\n",
    "MAXIMUM = ['difference_clicks', 'elapsed_time']\n",
    "\n",
    "\n",
    "\n",
    "def feature_engineer_steve(dataset_df):\n",
    "    dfs = []\n",
    "    tmp = dataset_df.groupby(['session_id','level'])[\"level_group\"].first()\n",
    "    tmp.name = tmp.name \n",
    "    dfs.append(tmp)\n",
    "    for c in CATEGORICAL:\n",
    "        if c not in ['fullscreen', 'hq', 'music']:\n",
    "            tmp = dataset_df.groupby(['session_id','level'])[c].agg('nunique')\n",
    "        else:\n",
    "            tmp = dataset_df.groupby(['session_id','level'])[c].first().astype(int).fillna(0)\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMERICALmean:\n",
    "        tmp = dataset_df.groupby(['session_id','level'])[c].agg('mean')\n",
    "        tmp.name = tmp.name + '_mean'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMERICALstd:\n",
    "        tmp = dataset_df.groupby(['session_id','level'])[c].agg('std')\n",
    "        tmp.name = tmp.name + '_std'\n",
    "        dfs.append(tmp)    \n",
    "    for c in COUNTING:\n",
    "        tmp = 1+ dataset_df.groupby(['session_id','level'])[c].agg('max')- dataset_df.groupby(['session_id','level'])[c].agg('min') \n",
    "        tmp.name = tmp.name + '_sum_of_actions'\n",
    "        dfs.append(tmp)\n",
    "    for c in MAXIMUM:\n",
    "        tmp = dataset_df.groupby(['session_id','level'])[c].agg('max')- dataset_df.groupby(['session_id','level'])[c].agg('min') \n",
    "        tmp.name = tmp.name + '_max'\n",
    "        dfs.append(tmp)\n",
    "    \n",
    "    dataset_df = pd.concat(dfs,axis=1)\n",
    "    dataset_df = dataset_df.fillna(-1)\n",
    "    dataset_df = dataset_df.reset_index()\n",
    "    dataset_df = dataset_df.set_index('session_id') \n",
    "    \n",
    "# add Clicks per second afterwards cause we need the time for each level first\n",
    "    dataset_df['clicks_per_second'] = dataset_df['index_sum_of_actions']/ dataset_df['elapsed_time_max']\n",
    " \n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              session_id  index  elapsed_time          event_name       name  \\\n",
      "0      20090312431273200      0         0.000      cutscene_click      basic   \n",
      "2      20090312431273200      2         0.831        person_click      basic   \n",
      "3      20090312431273200      3         1.147        person_click      basic   \n",
      "1      20090312431273200      1         1.323        person_click      basic   \n",
      "4      20090312431273200      4         1.863        person_click      basic   \n",
      "...                  ...    ...           ...                 ...        ...   \n",
      "19995  20090317080721164   1364      2454.048  notification_click      basic   \n",
      "19996  20090317080721164   1365      2455.479        object_click      basic   \n",
      "19997  20090317080721164   1366      2456.860        object_hover  undefined   \n",
      "19998  20090317080721164   1367      2457.726        object_click      basic   \n",
      "19999  20090317080721164   1368      2459.226  notification_click      basic   \n",
      "\n",
      "       level  page  room_coor_x  room_coor_y  screen_coor_x  ...  \\\n",
      "0          0   NaN  -413.991394  -159.314682          380.0  ...   \n",
      "2          0   NaN  -413.991394  -159.314682          380.0  ...   \n",
      "3          0   NaN  -413.991394  -159.314682          380.0  ...   \n",
      "1          0   NaN  -413.991394  -159.314682          380.0  ...   \n",
      "4          0   NaN  -412.991394  -159.314682          381.0  ...   \n",
      "...      ...   ...          ...          ...            ...  ...   \n",
      "19995     21   NaN   406.725525   -73.244423          771.0  ...   \n",
      "19996     21   NaN   406.725525   -73.244423          771.0  ...   \n",
      "19997     21   NaN          NaN          NaN            NaN  ...   \n",
      "19998     21   NaN  -101.274475    15.755580          263.0  ...   \n",
      "19999     21   NaN   423.725525   -83.244423          788.0  ...   \n",
      "\n",
      "       hover_duration                                         text  \\\n",
      "0                 NaN                                    undefined   \n",
      "2                 NaN                       Just talking to Teddy.   \n",
      "3                 NaN                   I gotta run to my meeting!   \n",
      "1                 NaN                Whatcha doing over there, Jo?   \n",
      "4                 NaN                          Can I come, Gramps?   \n",
      "...               ...                                          ...   \n",
      "19995             NaN  I should go to the Capitol and tell Mrs. M!   \n",
      "19996             NaN                                          NaN   \n",
      "19997          7826.0                                          NaN   \n",
      "19998             NaN                                          NaN   \n",
      "19999             NaN                 Look at all those activists!   \n",
      "\n",
      "                            fqid                       room_fqid  \\\n",
      "0                          intro  tunic.historicalsociety.closet   \n",
      "2                         gramps  tunic.historicalsociety.closet   \n",
      "3                         gramps  tunic.historicalsociety.closet   \n",
      "1                         gramps  tunic.historicalsociety.closet   \n",
      "4                         gramps  tunic.historicalsociety.closet   \n",
      "...                          ...                             ...   \n",
      "19995                        NaN  tunic.historicalsociety.stacks   \n",
      "19996   journals_flag.pic_2.next  tunic.historicalsociety.stacks   \n",
      "19997  journals_flag.pic_2.bingo  tunic.historicalsociety.stacks   \n",
      "19998  journals_flag.pic_0.bingo  tunic.historicalsociety.stacks   \n",
      "19999                        NaN  tunic.historicalsociety.stacks   \n",
      "\n",
      "                                               text_fqid fullscreen hq music  \\\n",
      "0                   tunic.historicalsociety.closet.intro          0  0     1   \n",
      "2      tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n",
      "3      tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n",
      "1      tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n",
      "4      tunic.historicalsociety.closet.gramps.intro_0_...          0  0     1   \n",
      "...                                                  ...        ... ..   ...   \n",
      "19995  tunic.historicalsociety.stacks.journals_flag.p...          0  0     1   \n",
      "19996                                                NaN          0  0     1   \n",
      "19997                                                NaN          0  0     1   \n",
      "19998                                                NaN          0  0     1   \n",
      "19999  tunic.historicalsociety.stacks.journals_flag.p...          0  0     1   \n",
      "\n",
      "      level_group difference_clicks  \n",
      "0             0-4             0.000  \n",
      "2             0-4             0.831  \n",
      "3             0-4             0.316  \n",
      "1             0-4             0.176  \n",
      "4             0-4             0.540  \n",
      "...           ...               ...  \n",
      "19995       13-22             0.808  \n",
      "19996       13-22             1.431  \n",
      "19997       13-22             1.381  \n",
      "19998       13-22             0.866  \n",
      "19999       13-22             1.500  \n",
      "\n",
      "[20000 rows x 21 columns]\n",
      "                   level level_group  event_name  name  fqid  room_fqid  \\\n",
      "session_id                                                                \n",
      "20090312431273200      0         0-4           6     3     5          1   \n",
      "20090312431273200      1         0-4           6     3     6          3   \n",
      "20090312431273200      2         0-4           6     3     8          2   \n",
      "20090312431273200      3         0-4           9     3    13          6   \n",
      "20090312431273200      4         0-4           4     2     5          2   \n",
      "...                  ...         ...         ...   ...   ...        ...   \n",
      "20090317080721164     17       13-22           4     4     5          4   \n",
      "20090317080721164     18       13-22          10     4    17          3   \n",
      "20090317080721164     19       13-22           7     4     9          2   \n",
      "20090317080721164     20       13-22           7     3    14          3   \n",
      "20090317080721164     21       13-22           8     4    15          5   \n",
      "\n",
      "                   text_fqid  fullscreen  hq  music  ...  room_coor_x_std  \\\n",
      "session_id                                           ...                    \n",
      "20090312431273200          6           0   0      1  ...       469.524328   \n",
      "20090312431273200          3           0   0      1  ...       358.166662   \n",
      "20090312431273200          5           0   0      1  ...       324.386196   \n",
      "20090312431273200          5           0   0      1  ...       389.874453   \n",
      "20090312431273200          0           0   0      1  ...       422.014525   \n",
      "...                      ...         ...  ..    ...  ...              ...   \n",
      "20090317080721164          2           0   0      1  ...       605.727392   \n",
      "20090317080721164         14           0   0      1  ...       539.819725   \n",
      "20090317080721164          5           0   0      1  ...       699.746370   \n",
      "20090317080721164          3           0   0      1  ...       277.277660   \n",
      "20090317080721164          4           0   0      1  ...       332.716483   \n",
      "\n",
      "                   room_coor_y_std  screen_coor_x_std  screen_coor_y_std  \\\n",
      "session_id                                                                 \n",
      "20090312431273200        84.862476         211.047234          87.147142   \n",
      "20090312431273200       116.538196         188.452544          89.020102   \n",
      "20090312431273200       158.503091         178.524529         106.028716   \n",
      "20090312431273200       117.002236         204.998931         106.129303   \n",
      "20090312431273200        41.143422         181.938451          39.566540   \n",
      "...                            ...                ...                ...   \n",
      "20090317080721164       190.298909         254.499702         126.715013   \n",
      "20090317080721164       278.060536         188.042548          94.995875   \n",
      "20090317080721164       334.139127         285.106399         152.887989   \n",
      "20090317080721164       121.906446         190.157612         114.305189   \n",
      "20090317080721164       126.627917         222.888578         112.787849   \n",
      "\n",
      "                   hover_duration_std  difference_clicks_std  \\\n",
      "session_id                                                     \n",
      "20090312431273200           -1.000000               0.473709   \n",
      "20090312431273200           -1.000000               1.068973   \n",
      "20090312431273200         2509.521966               0.520979   \n",
      "20090312431273200         3595.354271               0.886427   \n",
      "20090312431273200          164.755880               8.380692   \n",
      "...                               ...                    ...   \n",
      "20090317080721164           -1.000000               0.983913   \n",
      "20090317080721164         4256.798661               1.662691   \n",
      "20090317080721164          117.126712               1.301016   \n",
      "20090317080721164         3196.247205               1.395779   \n",
      "20090317080721164         2964.786606               1.445493   \n",
      "\n",
      "                   index_sum_of_actions  difference_clicks_max  \\\n",
      "session_id                                                       \n",
      "20090312431273200                    28                  1.784   \n",
      "20090312431273200                    32                  4.864   \n",
      "20090312431273200                    39                  2.215   \n",
      "20090312431273200                    53                  4.540   \n",
      "20090312431273200                    13                 30.837   \n",
      "...                                 ...                    ...   \n",
      "20090317080721164                    29                  4.382   \n",
      "20090317080721164                   135                 14.273   \n",
      "20090317080721164                    67                  6.045   \n",
      "20090317080721164                    49                  8.418   \n",
      "20090317080721164                    54                  8.560   \n",
      "\n",
      "                   elapsed_time_max  clicks_per_second  \n",
      "session_id                                              \n",
      "20090312431273200            25.766           1.086703  \n",
      "20090312431273200            37.346           0.856852  \n",
      "20090312431273200            34.253           1.138586  \n",
      "20090312431273200            54.712           0.968709  \n",
      "20090312431273200            38.621           0.336604  \n",
      "...                             ...                ...  \n",
      "20090317080721164            40.770           0.711307  \n",
      "20090317080721164           230.340           0.586090  \n",
      "20090317080721164            98.990           0.676836  \n",
      "20090317080721164            67.548           0.725410  \n",
      "20090317080721164            91.930           0.587403  \n",
      "\n",
      "[412 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#return the preprocessed data\n",
    "##test data preprocessing with Subset of 5 million rows\n",
    "\n",
    "dataset_df_added = adding_new_variables_rescaling(dataset_df)\n",
    "dataset_df_level = feature_engineer_steve(dataset_df_added)\n",
    "print(dataset_df_added)\n",
    "print(dataset_df_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "#dataset_df_added.to_csv('data/processed/data_df_added.csv')\n",
    "#dataset_df_level.to_csv('data/processed/data_df_level.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level                       uint64\n",
      "level_group               category\n",
      "event_name                   int64\n",
      "name                         int64\n",
      "fqid                         int64\n",
      "room_fqid                    int64\n",
      "text_fqid                    int64\n",
      "fullscreen                   int32\n",
      "hq                           int32\n",
      "music                        int32\n",
      "hover_duration_mean        float32\n",
      "difference_clicks_mean     float64\n",
      "elapsed_time_std           float64\n",
      "page_std                   float64\n",
      "room_coor_x_std            float64\n",
      "room_coor_y_std            float64\n",
      "screen_coor_x_std          float64\n",
      "screen_coor_y_std          float64\n",
      "hover_duration_std         float64\n",
      "difference_clicks_std      float64\n",
      "index_sum_of_actions         int32\n",
      "difference_clicks_max      float64\n",
      "elapsed_time_max           float64\n",
      "clicks_per_second          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset_df_level.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['level', 'level_group', 'event_name', 'name', 'fqid', 'room_fqid',\n",
       "       'text_fqid', 'fullscreen', 'hq', 'music', 'hover_duration_mean',\n",
       "       'difference_clicks_mean', 'elapsed_time_std', 'page_std',\n",
       "       'room_coor_x_std', 'room_coor_y_std', 'screen_coor_x_std',\n",
       "       'screen_coor_y_std', 'hover_duration_std', 'difference_clicks_std',\n",
       "       'index_sum_of_actions', 'difference_clicks_max', 'elapsed_time_max',\n",
       "       'clicks_per_second'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df_level.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataframe into three different ones depending on the level group\n",
    "groups = dataset_df_level.groupby('level_group')\n",
    "\n",
    "# Create a dictionary to store the resulting dataframes\n",
    "result = {}\n",
    "\n",
    "# Loop over each group\n",
    "for name, group in groups:\n",
    "    # Add the group to the result dictionary\n",
    "    result[name] = group\n",
    "\n",
    "# Access the resulting dataframes using their keys\n",
    "df_0_4 = result['0-4']\n",
    "df_5_12 = result['5-12']\n",
    "df_13_22 = result['13-22']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  col1_1  col2_1  col3_1  col1_2  col2_2  col3_2\n",
      "0         1.0     1.0       5     9.0     2.0       6    10.0\n",
      "1         2.0     NaN       7    11.0     4.0       8     NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sample data with NaN values\n",
    "df = pd.DataFrame({\n",
    "    'session_id': [1, 1, 2, 2],\n",
    "    'level_group': ['0-4', '0-4', '0-4', '0-4'],\n",
    "    'col1': [1, 2, np.nan, 4],\n",
    "    'col2': [5, 6, 7, 8],\n",
    "    'col3': [9, 10, 11, np.nan]\n",
    "})\n",
    "\n",
    "# get the unique session_ids and columns\n",
    "session_ids = df['session_id'].unique()\n",
    "cols = ['session_id'] + [f'{col}_{i+1}' for i in range(len(session_ids)) for col in ['col1', 'col2', 'col3']]\n",
    "\n",
    "# create a new dataframe to hold the flattened data\n",
    "new_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "# loop through each session_id\n",
    "for i, session_id in enumerate(session_ids):\n",
    "    df_session = df[df['session_id'] == session_id].reset_index(drop=True)\n",
    "    # combine the columns into a single row\n",
    "    row_data = [df_session[col].iloc[i] for i in range(len(df_session)) for col in ['col1', 'col2', 'col3']] \n",
    "    # add None values to the row if necessary to make it the same length as the columns\n",
    "    if len(row_data) < len(cols) - 1:\n",
    "        row_data += [None] * (len(cols) - len(row_data) - 1)\n",
    "    # add the session_id to the beginning of the row\n",
    "    row_data = [session_id] + row_data\n",
    "    # add the row to the new dataframe\n",
    "    new_df.loc[len(new_df)] = row_data\n",
    "\n",
    "# fill NaN values with np.nan\n",
    "new_df = new_df.fillna(np.nan)\n",
    "\n",
    "# convert the columns back to their original datatypes\n",
    "for col in ['col1', 'col2', 'col3']:\n",
    "    new_df[[f'{col}_{i+1}' for i in range(len(session_ids))]] = new_df[[f'{col}_{i+1}' for i in range(len(session_ids))]].astype(df[col].dtype, errors='ignore')\n",
    "\n",
    "# sort the columns\n",
    "new_df = new_df[cols]\n",
    "\n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def flatten_df(df):\n",
    "    # create a new index col\n",
    "    df = df.reset_index()\n",
    "    df['_index'] = df.index + 1\n",
    "    df = df.set_index('_index')\n",
    "    df = df.drop([\"level_group\"], axis= 1)\n",
    "\n",
    "    # get the unique session_ids and columns\n",
    "    session_ids = df['session_id'].unique()\n",
    "    cols = ['session_id'] + [f'{col}_{i+1}' for i in range(len(session_ids)) for col in df.columns if col != 'session_id']\n",
    "\n",
    "    # create a new dataframe to hold the flattened data\n",
    "    new_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    # loop through each session_id\n",
    "    for i, session_id in enumerate(session_ids):\n",
    "        df_session = df[df['session_id'] == session_id].reset_index(drop=True)\n",
    "        # combine the columns into a single row\n",
    "        row_data = [df_session[col].iloc[i] if pd.notnull(df_session[col].iloc[i]) else np.nan for i in range(len(df_session)) for col in df.columns if col != 'session_id'] \n",
    "        # add None values to the row if necessary to make it the same length as the columns\n",
    "        if len(row_data) < len(cols) - 1:\n",
    "            row_data += [np.nan] * (len(cols) - len(row_data) - 1)\n",
    "        # add the session_id to the beginning of the row\n",
    "        row_data = [session_id] + row_data\n",
    "        # add the row to the new dataframe\n",
    "        new_df.loc[len(new_df)] = row_data\n",
    "\n",
    "    # fill NaN values with np.nan\n",
    "    new_df = new_df.fillna(np.nan)\n",
    "\n",
    "    # convert the columns back to their original datatypes\n",
    "    for col in df.columns:\n",
    "        if col != 'session_id':\n",
    "            new_df[[f'{col}_{i+1}' for i in range(len(session_ids))]] = new_df[[f'{col}_{i+1}' for i in range(len(session_ids))]].astype(df[col].dtype, errors='ignore')\n",
    "\n",
    "    # sort the columns\n",
    "    new_df = new_df[cols]\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (185) does not match length of index (415)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mn:\\MASTER_DS\\Code\\Kaggle_competition\\Kaggle-seminar\\student-performance\\notebooks\\feature_engineer_playground_steve.ipynb Cell 13\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/feature_engineer_playground_steve.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m new_df \u001b[39m=\u001b[39m flatten_df(df_5_12)\n",
      "\u001b[1;32mn:\\MASTER_DS\\Code\\Kaggle_competition\\Kaggle-seminar\\student-performance\\notebooks\\feature_engineer_playground_steve.ipynb Cell 13\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/feature_engineer_playground_steve.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mSeries(row_data, index\u001b[39m=\u001b[39mcols)\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/feature_engineer_playground_steve.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# apply the function to each session_id group and concatenate the results\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/feature_engineer_playground_steve.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m new_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(grouped\u001b[39m.\u001b[39;49mapply(combine_cols))\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/feature_engineer_playground_steve.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# convert the columns back to their original datatypes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/feature_engineer_playground_steve.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m dtypes \u001b[39m=\u001b[39m {col: df[col]\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m col \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msession_id\u001b[39m\u001b[39m'\u001b[39m}\n",
      "File \u001b[1;32mn:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1549\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1547\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1548\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1549\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj)\n\u001b[0;32m   1550\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   1551\u001b[0m         \u001b[39m# gh-20949\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m         \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1556\u001b[0m         \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m         \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group_selection_context():\n",
      "File \u001b[1;32mn:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1601\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1565\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[0;32m   1566\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1571\u001b[0m     is_agg: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1572\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[0;32m   1573\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1599\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1601\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[0;32m   1602\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1603\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutated\n",
      "File \u001b[1;32mn:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:839\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[0;32m    838\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[1;32m--> 839\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[0;32m    840\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    841\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;32mn:\\MASTER_DS\\Code\\Kaggle_competition\\Kaggle-seminar\\student-performance\\notebooks\\feature_engineer_playground_steve.ipynb Cell 13\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/feature_engineer_playground_steve.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         row_data\u001b[39m.\u001b[39mextend(df_session[col]\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m     <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/feature_engineer_playground_steve.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m row_data \u001b[39m=\u001b[39m [df_session[\u001b[39m'\u001b[39m\u001b[39msession_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]] \u001b[39m+\u001b[39m row_data\n\u001b[1;32m---> <a href='vscode-notebook-cell:/n%3A/MASTER_DS/Code/Kaggle_competition/Kaggle-seminar/student-performance/notebooks/feature_engineer_playground_steve.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mSeries(row_data, index\u001b[39m=\u001b[39;49mcols)\n",
      "File \u001b[1;32mn:\\Python\\lib\\site-packages\\pandas\\core\\series.py:461\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    459\u001b[0m     index \u001b[39m=\u001b[39m default_index(\u001b[39mlen\u001b[39m(data))\n\u001b[0;32m    460\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n\u001b[1;32m--> 461\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(data, index)\n\u001b[0;32m    463\u001b[0m \u001b[39m# create/copy the manager\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "File \u001b[1;32mn:\\Python\\lib\\site-packages\\pandas\\core\\common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (185) does not match length of index (415)"
     ]
    }
   ],
   "source": [
    "new_df = flatten_df(df_5_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  index_1  col1_1  col2_1  col3_1  index_2  col1_2  col2_2  \\\n",
      "0           1        0       1       5       9        1       2       6   \n",
      "1           2        2       3       7      11        3       4       8   \n",
      "\n",
      "   col3_2  \n",
      "0      10  \n",
      "1      12  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'session_id': [1, 1, 2, 2],\n",
    "    'level_group': ['0-4', '0-4', '0-4', '0-4'],\n",
    "    'col1': [1, 2, 3, 4],\n",
    "    'col2': [5, 6, 7, 8],\n",
    "    'col3': [9, 10, 11, 12]\n",
    "})\n",
    "\n",
    "new_df_2 = flatten_df(df)\n",
    "\n",
    "print(new_df_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_4 = df_0_4.reset_index()\n",
    "df_0_4 = df_0_4.set_index('index')\n",
    "df_0_4 = df_0_4.drop([\"level_group\"], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def flatten_df(df):\n",
    "    # create a new index col\n",
    "    df = df.reset_index()\n",
    "    df['_index'] = df.index + 1\n",
    "    df = df.set_index('_index')\n",
    "    df = df.drop([\"level_group\"], axis= 1)\n",
    "\n",
    "    # get the unique session_ids and columns\n",
    "    session_ids = df['session_id'].unique()\n",
    "    cols = ['session_id'] + [f'{col}_{i+1}' for i in range(len(session_ids)) for col in df.columns if col != 'session_id']\n",
    "\n",
    "    # create a list to hold the flattened data\n",
    "    rows = []\n",
    "\n",
    "    # loop through each session_id\n",
    "    for session_id in session_ids:\n",
    "        df_session = df[df['session_id'] == session_id].reset_index(drop=True)\n",
    "        # combine the columns into a single row\n",
    "        row_data = [df_session[col].iloc[i] if pd.notnull(df_session[col].iloc[i]) else np.nan for i in range(len(df_session)) for col in df.columns if col != 'session_id'] \n",
    "        # add None values to the row if necessary to make it the same length as the columns\n",
    "        if len(row_data) < len(cols) - 1:\n",
    "            row_data += [np.nan] * (len(cols) - len(row_data) - 1)\n",
    "        # add the session_id to the beginning of the row\n",
    "        row_data = [session_id] + row_data\n",
    "        # append the row to the list\n",
    "        rows.append(row_data)\n",
    "\n",
    "    # create the new dataframe from the list\n",
    "    new_df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "    # fill NaN values with np.nan\n",
    "    new_df = new_df.fillna(np.nan)\n",
    "\n",
    "    # convert the columns back to their original datatypes\n",
    "    for col in df.columns:\n",
    "        if col != 'session_id':\n",
    "            new_df[[f'{col}_{i+1}' for i in range(len(session_ids))]] = new_df[[f'{col}_{i+1}' for i in range(len(session_ids))]].astype(df[col].dtype, errors='ignore')\n",
    "\n",
    "    # sort the columns\n",
    "    new_df = new_df[cols]\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def flatten_df(df):\n",
    "    # create a new index col\n",
    "    df = df.reset_index()\n",
    "    df['_index'] = df.index + 1\n",
    "    df = df.set_index('_index')\n",
    "    df = df.drop([\"level_group\"], axis= 1)\n",
    "\n",
    "    # group by session_id\n",
    "    grouped = df.groupby('session_id')\n",
    "\n",
    "    # get the unique session_ids and columns\n",
    "    session_ids = grouped.groups.keys()\n",
    "    cols = ['session_id'] + [f'{col}_{i+1}' for i in range(len(session_ids)) for col in df.columns if col != 'session_id']\n",
    "\n",
    "    # create a new dataframe to hold the flattened data\n",
    "    new_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    # define a function to combine columns into a single row\n",
    "    def combine_cols(df_session):\n",
    "        row_data = []\n",
    "        for col in df.columns:\n",
    "            if col != 'session_id':\n",
    "                row_data.extend(df_session[col].tolist())\n",
    "        row_data = [df_session['session_id'].iloc[0]] + row_data\n",
    "        return pd.Series(row_data, index=cols)\n",
    "\n",
    "    # apply the function to each session_id group and concatenate the results\n",
    "    new_df = pd.concat(grouped.apply(combine_cols))\n",
    "\n",
    "    # convert the columns back to their original datatypes\n",
    "    dtypes = {col: df[col].dtype for col in df.columns if col != 'session_id'}\n",
    "    new_df = new_df.astype(dtypes, errors='ignore')\n",
    "\n",
    "    return new_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
