{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###Imports for the Data Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory:  N:\\MASTER_DS\n"
     ]
    }
   ],
   "source": [
    "# get working directory and remove last folder\n",
    "# TODO: make this more robust\n",
    "wd = os.path.dirname(os.getcwd())\n",
    "os.chdir(wd)\n",
    "print(\"Working Directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes={\n",
    "    'elapsed_time':np.int32,\n",
    "    'event_name':'category',\n",
    "    'name':'category',\n",
    "    'level':np.uint8,\n",
    "    'room_coor_x':np.float32,\n",
    "    \"index\": np.int32,\n",
    "    'room_coor_y':np.float32,\n",
    "    'screen_coor_x':np.float32,\n",
    "    'screen_coor_y':np.float32,\n",
    "    'hover_duration':np.float32,\n",
    "    'text':'category',\n",
    "    'fqid':'category',\n",
    "    'room_fqid':'category',\n",
    "    'text_fqid':'category',\n",
    "    'fullscreen':'category',\n",
    "    'hq':'category',\n",
    "    'music':'category',\n",
    "    'level_group':'category'}\n",
    "\n",
    "\n",
    "os.chdir(\"N:\\MASTER_DS\\Code\\Kaggle_competition\\Kaggle-seminar\\student-performance\")\n",
    "dataset_df = pd.read_csv('data/raw/train.csv', dtype=dtypes, nrows= 2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing function to add variables and rescale the time \n",
    "def adding_new_variables_rescaling(dataset_df):\n",
    "    dataset_df = dataset_df.sort_values(['session_id','elapsed_time'])\n",
    "    dataset_df[\"elapsed_time\"] = dataset_df[\"elapsed_time\"]/1000\n",
    "    group = dataset_df.groupby([\"session_id\",\"level\"])[\"elapsed_time\"].diff()\n",
    "    group = group.fillna(value= 0)\n",
    "    dataset_df= dataset_df.assign(difference_clicks = group)\n",
    "\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing to combine variables on level stage\n",
    "#Function to clean the sequential data for the training of the model\n",
    "\n",
    "#For that Function to work we need to specify the variables in Categorical and Numerical & Counting\n",
    "\n",
    "CATEGORICAL = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
    "NUMERICALmean = ['hover_duration',\"difference_clicks\"]\n",
    "NUMERICALstd = ['elapsed_time','page','room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration',\"difference_clicks\"]\n",
    "COUNTING = [\"index\"]\n",
    "MAXIMUM = [\"difference_clicks\", \"elapsed_time\"]\n",
    "\n",
    "def feature_engineer_steve(dataset_df):\n",
    "    dfs = []\n",
    "    #add the level group again to make training on the sequential data easier\n",
    "    tmp = dataset_df.groupby(['session_id','level'])[\"level_group\"].first()\n",
    "    dfs.append(tmp)\n",
    "    for c in CATEGORICAL:\n",
    "        tmp = dataset_df.groupby(['session_id','level'])[c].agg('nunique')\n",
    "        tmp.name = tmp.name + '_nunique'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMERICALmean:\n",
    "        tmp = dataset_df.groupby(['session_id','level'])[c].agg('mean')\n",
    "        tmp.name = tmp.name + '_mean'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMERICALstd:\n",
    "        tmp = dataset_df.groupby(['session_id','level'])[c].agg('std')\n",
    "        tmp.name = tmp.name + '_std'\n",
    "        dfs.append(tmp)    \n",
    "    for c in COUNTING:\n",
    "        tmp = 1+ dataset_df.groupby(['session_id','level'])[c].agg('max')- dataset_df.groupby(['session_id','level'])[c].agg('min') \n",
    "        tmp.name = tmp.name + '_sum_of_actions'\n",
    "        dfs.append(tmp)\n",
    "    for c in MAXIMUM:\n",
    "        tmp = dataset_df.groupby(['session_id','level'])[c].agg('max')- dataset_df.groupby(['session_id','level'])[c].agg('min') \n",
    "        tmp.name = tmp.name + '_max'\n",
    "        dfs.append(tmp)\n",
    "    \n",
    "    dataset_df = pd.concat(dfs,axis=1)\n",
    "    dataset_df = dataset_df.fillna(-1)\n",
    "    dataset_df = dataset_df.reset_index()\n",
    "    dataset_df = dataset_df.set_index('session_id')\n",
    "    \n",
    "     #add Clicks per second afterwards cause we need the time for each level first\n",
    "    dataset_df[\"clicks_per_second\"] = dataset_df[\"index_sum_of_actions\"]/ dataset_df[\"elapsed_time_max\"]\n",
    "    \n",
    "    \n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                session_id  index  elapsed_time      event_name       name  \\\n",
      "0        20090312431273200      0         0.000  cutscene_click      basic   \n",
      "2        20090312431273200      2         0.831    person_click      basic   \n",
      "3        20090312431273200      3         1.147    person_click      basic   \n",
      "1        20090312431273200      1         1.323    person_click      basic   \n",
      "4        20090312431273200      4         1.863    person_click      basic   \n",
      "...                    ...    ...           ...             ...        ...   \n",
      "1999995  20110211310637800    472       802.324  navigate_click  undefined   \n",
      "1999996  20110211310637800    473       802.625  navigate_click  undefined   \n",
      "1999997  20110211310637800    474       802.900  navigate_click  undefined   \n",
      "1999998  20110211310637800    475       803.451    object_hover      basic   \n",
      "1999999  20110211310637800    476       805.500    object_hover  undefined   \n",
      "\n",
      "         level  page  room_coor_x  room_coor_y  screen_coor_x  ...  \\\n",
      "0            0   NaN  -413.991394  -159.314682          380.0  ...   \n",
      "2            0   NaN  -413.991394  -159.314682          380.0  ...   \n",
      "3            0   NaN  -413.991394  -159.314682          380.0  ...   \n",
      "1            0   NaN  -413.991394  -159.314682          380.0  ...   \n",
      "4            0   NaN  -412.991394  -159.314682          381.0  ...   \n",
      "...        ...   ...          ...          ...            ...  ...   \n",
      "1999995      9   NaN    -0.443521   108.000000          442.0  ...   \n",
      "1999996      9   NaN   -24.435286   114.000000          420.0  ...   \n",
      "1999997      9   NaN   -49.537674    98.000000          396.0  ...   \n",
      "1999998      9   NaN          NaN          NaN            NaN  ...   \n",
      "1999999      9   NaN          NaN          NaN            NaN  ...   \n",
      "\n",
      "         hover_duration                           text                fqid  \\\n",
      "0                   NaN                      undefined               intro   \n",
      "2                   NaN         Just talking to Teddy.              gramps   \n",
      "3                   NaN     I gotta run to my meeting!              gramps   \n",
      "1                   NaN  Whatcha doing over there, Jo?              gramps   \n",
      "4                   NaN            Can I come, Gramps?              gramps   \n",
      "...                 ...                            ...                 ...   \n",
      "1999995             NaN                            NaN              reader   \n",
      "1999996             NaN                            NaN              reader   \n",
      "1999997             NaN                            NaN              reader   \n",
      "1999998           525.0                            NaN              reader   \n",
      "1999999            75.0                            NaN  reader.paper0.next   \n",
      "\n",
      "                              room_fqid  \\\n",
      "0        tunic.historicalsociety.closet   \n",
      "2        tunic.historicalsociety.closet   \n",
      "3        tunic.historicalsociety.closet   \n",
      "1        tunic.historicalsociety.closet   \n",
      "4        tunic.historicalsociety.closet   \n",
      "...                                 ...   \n",
      "1999995        tunic.library.microfiche   \n",
      "1999996        tunic.library.microfiche   \n",
      "1999997        tunic.library.microfiche   \n",
      "1999998        tunic.library.microfiche   \n",
      "1999999        tunic.library.microfiche   \n",
      "\n",
      "                                                 text_fqid fullscreen hq  \\\n",
      "0                     tunic.historicalsociety.closet.intro          0  0   \n",
      "2        tunic.historicalsociety.closet.gramps.intro_0_...          0  0   \n",
      "3        tunic.historicalsociety.closet.gramps.intro_0_...          0  0   \n",
      "1        tunic.historicalsociety.closet.gramps.intro_0_...          0  0   \n",
      "4        tunic.historicalsociety.closet.gramps.intro_0_...          0  0   \n",
      "...                                                    ...        ... ..   \n",
      "1999995                                                NaN          0  0   \n",
      "1999996                                                NaN          0  0   \n",
      "1999997                                                NaN          0  0   \n",
      "1999998                                                NaN          0  0   \n",
      "1999999                                                NaN          0  0   \n",
      "\n",
      "        music level_group difference_clicks  \n",
      "0           1         0-4             0.000  \n",
      "2           1         0-4             0.831  \n",
      "3           1         0-4             0.316  \n",
      "1           1         0-4             0.176  \n",
      "4           1         0-4             0.540  \n",
      "...       ...         ...               ...  \n",
      "1999995     1        5-12             0.325  \n",
      "1999996     1        5-12             0.301  \n",
      "1999997     1        5-12             0.275  \n",
      "1999998     1        5-12             0.551  \n",
      "1999999     1        5-12             2.049  \n",
      "\n",
      "[2000000 rows x 21 columns]\n",
      "                   level level_group  event_name_nunique  name_nunique  \\\n",
      "session_id                                                               \n",
      "20090312431273200      0         0-4                   6             3   \n",
      "20090312431273200      1         0-4                   6             3   \n",
      "20090312431273200      2         0-4                   6             3   \n",
      "20090312431273200      3         0-4                   9             3   \n",
      "20090312431273200      4         0-4                   4             2   \n",
      "...                  ...         ...                 ...           ...   \n",
      "20110211310637800      5        5-12                   4             2   \n",
      "20110211310637800      6        5-12                   4             2   \n",
      "20110211310637800      7        5-12                   7             3   \n",
      "20110211310637800      8        5-12                   7             3   \n",
      "20110211310637800      9        5-12                   5             2   \n",
      "\n",
      "                   fqid_nunique  room_fqid_nunique  text_fqid_nunique  \\\n",
      "session_id                                                              \n",
      "20090312431273200             5                  1                  6   \n",
      "20090312431273200             6                  3                  3   \n",
      "20090312431273200             8                  2                  5   \n",
      "20090312431273200            13                  6                  5   \n",
      "20090312431273200             5                  2                  0   \n",
      "...                         ...                ...                ...   \n",
      "20110211310637800             5                  4                  1   \n",
      "20110211310637800             9                  5                 10   \n",
      "20110211310637800            12                  4                  4   \n",
      "20110211310637800             5                  2                  3   \n",
      "20110211310637800             7                  3                  3   \n",
      "\n",
      "                   hover_duration_mean  difference_clicks_mean  \\\n",
      "session_id                                                       \n",
      "20090312431273200            -1.000000                0.920214   \n",
      "20090312431273200          7899.000000                1.167063   \n",
      "20090312431273200          2174.500000                0.878282   \n",
      "20090312431273200          2200.333252                1.032302   \n",
      "20090312431273200           133.500000                2.970846   \n",
      "...                                ...                     ...   \n",
      "20110211310637800           599.500000                0.927913   \n",
      "20110211310637800            -1.000000                1.773417   \n",
      "20110211310637800          1660.000000                1.608982   \n",
      "20110211310637800          1843.250000                1.878074   \n",
      "20110211310637800           391.500000                1.700738   \n",
      "\n",
      "                   elapsed_time_std  ...  room_coor_x_std  room_coor_y_std  \\\n",
      "session_id                           ...                                     \n",
      "20090312431273200          8.145743  ...       469.524328        84.862476   \n",
      "20090312431273200         10.584366  ...       358.166662       116.538196   \n",
      "20090312431273200         10.701095  ...       324.386196       158.503091   \n",
      "20090312431273200         16.499406  ...       389.874453       117.002236   \n",
      "20090312431273200         10.018629  ...       422.014525        41.143422   \n",
      "...                             ...  ...              ...              ...   \n",
      "20110211310637800          6.322782  ...       486.865775       175.233969   \n",
      "20110211310637800         52.928871  ...       351.017406       101.746670   \n",
      "20110211310637800         26.271071  ...       221.224666       108.115513   \n",
      "20110211310637800         34.326601  ...       208.607278        81.961664   \n",
      "20110211310637800         30.196582  ...       297.104350        86.226834   \n",
      "\n",
      "                   screen_coor_x_std  screen_coor_y_std  hover_duration_std  \\\n",
      "session_id                                                                    \n",
      "20090312431273200         211.047234          87.147142           -1.000000   \n",
      "20090312431273200         188.452544          89.020102           -1.000000   \n",
      "20090312431273200         178.524529         106.028716         2509.521966   \n",
      "20090312431273200         204.998931         106.129303         3595.354271   \n",
      "20090312431273200         181.938451          39.566540          164.755880   \n",
      "...                              ...                ...                 ...   \n",
      "20110211310637800         191.269045         111.944842          531.037193   \n",
      "20110211310637800         194.807946          91.434613           -1.000000   \n",
      "20110211310637800         149.572908         102.861327         2085.071382   \n",
      "20110211310637800         165.976487          81.961664         2646.333863   \n",
      "20110211310637800         179.065103          77.328661          213.058443   \n",
      "\n",
      "                   difference_clicks_std  index_sum_of_actions  \\\n",
      "session_id                                                       \n",
      "20090312431273200               0.473709                    28   \n",
      "20090312431273200               1.068973                    32   \n",
      "20090312431273200               0.520979                    39   \n",
      "20090312431273200               0.886427                    53   \n",
      "20090312431273200               8.380692                    13   \n",
      "...                                  ...                   ...   \n",
      "20110211310637800               1.034707                    23   \n",
      "20110211310637800               1.285995                   103   \n",
      "20110211310637800               1.150900                    55   \n",
      "20110211310637800               2.045204                    54   \n",
      "20110211310637800               2.439492                    61   \n",
      "\n",
      "                   difference_clicks_max  elapsed_time_max  clicks_per_second  \n",
      "session_id                                                                     \n",
      "20090312431273200                  1.784            25.766           1.086703  \n",
      "20090312431273200                  4.864            37.346           0.856852  \n",
      "20090312431273200                  2.215            34.253           1.138586  \n",
      "20090312431273200                  4.540            54.712           0.968709  \n",
      "20090312431273200                 30.837            38.621           0.336604  \n",
      "...                                  ...               ...                ...  \n",
      "20110211310637800                  3.474            21.342           1.077687  \n",
      "20110211310637800                  5.050           182.662           0.563883  \n",
      "20110211310637800                  5.000            88.494           0.621511  \n",
      "20110211310637800                 11.022           101.416           0.532460  \n",
      "20110211310637800                 16.570           103.745           0.587980  \n",
      "\n",
      "[40954 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#return the preprocessed data\n",
    "##test data preprocessing with Subset of 5 million rows\n",
    "\n",
    "\n",
    "dataset_df_added = adding_new_variables_rescaling(dataset_df)\n",
    "dataset_df_level = feature_engineer_steve(dataset_df_added)\n",
    "print(dataset_df_added)\n",
    "print(dataset_df_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_id         level_group\n",
      "20090312431273200  0-4              0-4\n",
      "                   13-22          13-22\n",
      "                   5-12            5-12\n",
      "20090312433251036  0-4              0-4\n",
      "                   13-22          13-22\n",
      "                                  ...  \n",
      "20110211305198484  13-22          13-22\n",
      "                   5-12            5-12\n",
      "20110211310637800  0-4              0-4\n",
      "                   13-22            NaN\n",
      "                   5-12            5-12\n",
      "Name: level_group, Length: 5349, dtype: category\n",
      "Categories (3, object): ['0-4', '13-22', '5-12']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_df.groupby(['session_id','level_group'])[\"level_group\"].first())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will build the function to load the training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to throw out some cols of the training dataset before saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['level', 'level_group', 'event_name_nunique', 'name_nunique', 'fqid_nunique', 'room_fqid_nunique', 'text_fqid_nunique', 'hover_duration_mean', 'difference_clicks_mean', 'elapsed_time_std', 'page_std', 'room_coor_x_std', 'room_coor_y_std', 'screen_coor_x_std', 'screen_coor_y_std', 'hover_duration_std', 'difference_clicks_std', 'index_sum_of_actions', 'difference_clicks_max', 'elapsed_time_max', 'clicks_per_second']\n"
     ]
    }
   ],
   "source": [
    "column_names = list(dataset_df_level.columns)\n",
    "print(column_names)\n",
    "\n",
    "dtypes={\n",
    "    \"level_group\": \"category\",\n",
    "    'level': np.uint8,\n",
    "    'event_name_nunique': np.uint8,\n",
    "    'name_nunique':np.uint8,\n",
    "    'fqid_nunique':np.uint8,\n",
    "    'room_fqid_nunique':np.uint8,\n",
    "    'text_fqid_nunique':np.uint8, \n",
    "    'hover_duration_mean': np.float32,\n",
    "    'difference_clicks_mean':np.float32,\n",
    "    'elapsed_time_std':np.float32,\n",
    "    'page_std':np.float32,\n",
    "    'room_coor_x_std':np.float32,\n",
    "    'room_coor_y_std':np.float32,\n",
    "    'screen_coor_x_std':np.float32,\n",
    "    'screen_coor_y_std':np.float32,\n",
    "    'hover_duration_std':np.float32,\n",
    "    'difference_clicks_std':np.float32,\n",
    "    'index_sum_of_actions':np.uint16,\n",
    "    'difference_clicks_max':np.float32,\n",
    "    'elapsed_time_max':np.float32,\n",
    "    'clicks_per_second':np.float32\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32761 examples in training, 8193 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(dataset, test_ratio=0.30):\n",
    "    USER_LIST = dataset.index.unique()\n",
    "    split = int(len(USER_LIST) * (1 - 0.20))\n",
    "    return dataset.loc[USER_LIST[:split]], dataset.loc[USER_LIST[split:]]\n",
    "\n",
    "train_x, valid_x = split_dataset(dataset_df_level)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_x), len(valid_x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the unique list of user sessions in the validation dataset. We assigned \n",
    "# `session_id` as the index of our feature engineered dataset. Hence fetching \n",
    "# the unique values in the index column will give us a list of users in the \n",
    "# validation set.\n",
    "VALID_USER_LIST = valid_x.index.unique()\n",
    "\n",
    "# Create a dataframe for storing the predictions of each question for all users\n",
    "# in the validation set.\n",
    "# For this, the required size of the data frame is: \n",
    "# (no: of users in validation set  x no of questions).\n",
    "# We will initialize all the predicted values in the data frame to zero.\n",
    "# The dataframe's index column is the user `session_id`s. \n",
    "prediction_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
    "\n",
    "# Create an empty dictionary to store the models created for each question.\n",
    "models = {}\n",
    "\n",
    "# Create an empty dictionary to store the evaluation score for each question.\n",
    "evaluation_dict ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through questions 1 to 18 to train models for each question, evaluate\n",
    "# the trained model and store the predicted values.\n",
    "for q_no in range(1,19):\n",
    "\n",
    "    # Select level group for the question based on the q_no.\n",
    "    if q_no<=3: grp = '0-4'\n",
    "    elif q_no<=13: grp = '5-12'\n",
    "    elif q_no<=22: grp = '13-22'\n",
    "    print(\"### q_no\", q_no, \"grp\", grp)\n",
    "    \n",
    "        \n",
    "    # Filter the rows in the datasets based on the selected level group. \n",
    "    train_df = train_x.loc[train_x.level_group == grp]\n",
    "    train_users = train_df.index.values\n",
    "    valid_df = valid_x.loc[valid_x.level_group == grp]\n",
    "    valid_users = valid_df.index.values\n",
    "\n",
    "    # Select the labels for the related q_no.\n",
    "    train_labels = labels.loc[labels.q==q_no].set_index('session').loc[train_users]\n",
    "    valid_labels = labels.loc[labels.q==q_no].set_index('session').loc[valid_users]\n",
    "\n",
    "    # Add the label to the filtered datasets.\n",
    "    train_df[\"correct\"] = train_labels[\"correct\"]\n",
    "    valid_df[\"correct\"] = valid_labels[\"correct\"]\n",
    "\n",
    "    # There's one more step required before we can train the model. \n",
    "    # We need to convert the datatset from Pandas format (pd.DataFrame)\n",
    "    # into TensorFlow Datasets format (tf.data.Dataset).\n",
    "    # TensorFlow Datasets is a high performance data loading library \n",
    "    # which is helpful when training neural networks with accelerators like GPUs and TPUs.\n",
    "    # We are omitting `level_group`, since it is not needed for training anymore.\n",
    "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df.loc[:, train_df.columns != 'level_group'], label=\"correct\")\n",
    "    valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_df.loc[:, valid_df.columns != 'level_group'], label=\"correct\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
