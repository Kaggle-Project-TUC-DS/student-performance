{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /Users/nzuchna/Desktop/Drive/2. Areas/University/Master-TUC/M2/4_Forschungsmodul/student-performance/notebooks\n",
      "New working directory:  /Users/nzuchna/Desktop/Drive/2. Areas/University/Master-TUC/M2/4_Forschungsmodul/student-performance\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.loader_steve import load_all_X_y\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set correct working directory\n",
    "wd = os.getcwd()\n",
    "print(\"Current working directory: \", wd)\n",
    "if wd[-9:] == \"notebooks\": wd = wd[:-10]\n",
    "else: print(\"Make sure your working directory is set to the student-performance folder!\")\n",
    "os.chdir(wd)\n",
    "print(\"New working directory: \", os.getcwd())\n",
    "\n",
    "data_all, labels = load_all_X_y()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6421 17141]\n",
      "0.2725150666327137 0.7274849333672863\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(\"data/processed/labels.csv\")\n",
    "y = labels['correct'][labels['q'] == 1].values\n",
    "dist = np.unique(y, return_counts=True)[1]  # [0, 1]\n",
    "print(dist)\n",
    "prob_0 = dist[0] / (dist[0] + dist[1])\n",
    "prob_1 = dist[1] / (dist[0] + dist[1])\n",
    "print(prob_0, prob_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "            session_id_1 level_group_1  event_name_1  name_1  fqid_1  \\\n0      20090312431273200          5-12             5       2       6   \n1      20090312433251036          5-12             5       2       8   \n2      20090312455206810          5-12             4       2       6   \n3      20090313091715820          5-12             5       4       7   \n4      20090313571836404          5-12             4       2       6   \n...                  ...           ...           ...     ...     ...   \n23557  22100215342220508          5-12             4       3       7   \n23558  22100215460321130          5-12             7       3      10   \n23559  22100217104993650          5-12             4       3       7   \n23560  22100219442786200          5-12             4       2       6   \n23561  22100221145014656          5-12             5       2       9   \n\n       room_fqid_1  text_fqid_1  fullscreen_1  hq_1  music_1  ...  page_std_8  \\\n0                4            2             0     0        1  ...   -1.000000   \n1                5            3             0     0        0  ...    0.000000   \n2                4            1             1     1        1  ...    0.000000   \n3                5            1             1     1        1  ...   -1.000000   \n4                4            1             0     0        1  ...   -1.000000   \n...            ...          ...           ...   ...      ...  ...         ...   \n23557            5            2             1     0        1  ...   -1.000000   \n23558            5            2             0     0        1  ...   -1.000000   \n23559            4            1             0     0        1  ...    0.000000   \n23560            4            1             0     0        1  ...    1.100505   \n23561            6            2             0     0        1  ...    0.000000   \n\n       hover_duration_std_8  difference_clicks_std_8  distance_clicks_std_8  \\\n0                106.066017                 0.617889             334.101776   \n1                176.776703                 1.440249             434.543121   \n2                 62.851677                 0.842236             495.198303   \n3                 -1.000000                 1.212265             253.962982   \n4                 -1.000000                 0.619625             205.166504   \n...                     ...                      ...                    ...   \n23557             60.324123                 2.230104             328.046783   \n23558             -1.000000                 1.328251             343.401031   \n23559             -1.000000                 0.678011             391.206177   \n23560            248.901581                 0.953770             347.272583   \n23561             -1.000000                 1.760621             349.826538   \n\n       screen_distance_clicks_std_8  index_sum_of_actions_8  \\\n0                        271.571899                      10   \n1                        275.379242                      10   \n2                        451.574158                      10   \n3                        234.349609                      10   \n4                        229.803146                       8   \n...                             ...                     ...   \n23557                    271.191864                       9   \n23558                    290.064606                       6   \n23559                    235.494781                      29   \n23560                    321.641907                      18   \n23561                    368.188538                      10   \n\n       difference_clicks_max_8  elapsed_time_max_8  sum_distance_clicks_max_8  \\\n0                        1.966               8.089                1720.914062   \n1                        5.155              18.548                3243.648438   \n2                        2.215              10.910                3210.085938   \n3                        4.145              12.855                2095.898438   \n4                        1.972               9.890                2142.171875   \n...                        ...                 ...                        ...   \n23557                    6.975              14.920                1761.117188   \n23558                    3.980              11.268                1665.062500   \n23559                    2.750              28.268               10165.039062   \n23560                    3.474              19.150                3709.859375   \n23561                    5.886              15.730                3556.242188   \n\n       clicks_per_second_8  \n0                 1.236247  \n1                 0.539142  \n2                 0.916590  \n3                 0.777907  \n4                 0.808898  \n...                    ...  \n23557             0.603217  \n23558             0.532481  \n23559             1.025895  \n23560             0.939948  \n23561             0.635728  \n\n[23562 rows x 165 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session_id_1</th>\n      <th>level_group_1</th>\n      <th>event_name_1</th>\n      <th>name_1</th>\n      <th>fqid_1</th>\n      <th>room_fqid_1</th>\n      <th>text_fqid_1</th>\n      <th>fullscreen_1</th>\n      <th>hq_1</th>\n      <th>music_1</th>\n      <th>...</th>\n      <th>page_std_8</th>\n      <th>hover_duration_std_8</th>\n      <th>difference_clicks_std_8</th>\n      <th>distance_clicks_std_8</th>\n      <th>screen_distance_clicks_std_8</th>\n      <th>index_sum_of_actions_8</th>\n      <th>difference_clicks_max_8</th>\n      <th>elapsed_time_max_8</th>\n      <th>sum_distance_clicks_max_8</th>\n      <th>clicks_per_second_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20090312431273200</td>\n      <td>5-12</td>\n      <td>5</td>\n      <td>2</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>106.066017</td>\n      <td>0.617889</td>\n      <td>334.101776</td>\n      <td>271.571899</td>\n      <td>10</td>\n      <td>1.966</td>\n      <td>8.089</td>\n      <td>1720.914062</td>\n      <td>1.236247</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20090312433251036</td>\n      <td>5-12</td>\n      <td>5</td>\n      <td>2</td>\n      <td>8</td>\n      <td>5</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>176.776703</td>\n      <td>1.440249</td>\n      <td>434.543121</td>\n      <td>275.379242</td>\n      <td>10</td>\n      <td>5.155</td>\n      <td>18.548</td>\n      <td>3243.648438</td>\n      <td>0.539142</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20090312455206810</td>\n      <td>5-12</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>62.851677</td>\n      <td>0.842236</td>\n      <td>495.198303</td>\n      <td>451.574158</td>\n      <td>10</td>\n      <td>2.215</td>\n      <td>10.910</td>\n      <td>3210.085938</td>\n      <td>0.916590</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20090313091715820</td>\n      <td>5-12</td>\n      <td>5</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>1.212265</td>\n      <td>253.962982</td>\n      <td>234.349609</td>\n      <td>10</td>\n      <td>4.145</td>\n      <td>12.855</td>\n      <td>2095.898438</td>\n      <td>0.777907</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20090313571836404</td>\n      <td>5-12</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.619625</td>\n      <td>205.166504</td>\n      <td>229.803146</td>\n      <td>8</td>\n      <td>1.972</td>\n      <td>9.890</td>\n      <td>2142.171875</td>\n      <td>0.808898</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23557</th>\n      <td>22100215342220508</td>\n      <td>5-12</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>60.324123</td>\n      <td>2.230104</td>\n      <td>328.046783</td>\n      <td>271.191864</td>\n      <td>9</td>\n      <td>6.975</td>\n      <td>14.920</td>\n      <td>1761.117188</td>\n      <td>0.603217</td>\n    </tr>\n    <tr>\n      <th>23558</th>\n      <td>22100215460321130</td>\n      <td>5-12</td>\n      <td>7</td>\n      <td>3</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>1.328251</td>\n      <td>343.401031</td>\n      <td>290.064606</td>\n      <td>6</td>\n      <td>3.980</td>\n      <td>11.268</td>\n      <td>1665.062500</td>\n      <td>0.532481</td>\n    </tr>\n    <tr>\n      <th>23559</th>\n      <td>22100217104993650</td>\n      <td>5-12</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.678011</td>\n      <td>391.206177</td>\n      <td>235.494781</td>\n      <td>29</td>\n      <td>2.750</td>\n      <td>28.268</td>\n      <td>10165.039062</td>\n      <td>1.025895</td>\n    </tr>\n    <tr>\n      <th>23560</th>\n      <td>22100219442786200</td>\n      <td>5-12</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.100505</td>\n      <td>248.901581</td>\n      <td>0.953770</td>\n      <td>347.272583</td>\n      <td>321.641907</td>\n      <td>18</td>\n      <td>3.474</td>\n      <td>19.150</td>\n      <td>3709.859375</td>\n      <td>0.939948</td>\n    </tr>\n    <tr>\n      <th>23561</th>\n      <td>22100221145014656</td>\n      <td>5-12</td>\n      <td>5</td>\n      <td>2</td>\n      <td>9</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>1.760621</td>\n      <td>349.826538</td>\n      <td>368.188538</td>\n      <td>10</td>\n      <td>5.886</td>\n      <td>15.730</td>\n      <td>3556.242188</td>\n      <td>0.635728</td>\n    </tr>\n  </tbody>\n</table>\n<p>23562 rows Ã— 165 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['5_12']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for question 1, accuracy: 0.73, f1_score: 0.84\n",
      "Trained model for question 2, accuracy: 0.98, f1_score: 0.99\n",
      "Trained model for question 3, accuracy: 0.93, f1_score: 0.97\n",
      "Trained model for question 4, accuracy: 0.8, f1_score: 0.89\n",
      "Trained model for question 5, accuracy: 0.55, f1_score: 0.71\n",
      "Trained model for question 6, accuracy: 0.78, f1_score: 0.87\n",
      "Trained model for question 7, accuracy: 0.74, f1_score: 0.85\n",
      "Trained model for question 8, accuracy: 0.62, f1_score: 0.76\n",
      "Trained model for question 9, accuracy: 0.74, f1_score: 0.85\n",
      "Trained model for question 10, accuracy: 0.51, f1_score: 0.67\n",
      "Trained model for question 11, accuracy: 0.64, f1_score: 0.78\n",
      "Trained model for question 12, accuracy: 0.86, f1_score: 0.93\n",
      "Trained model for question 13, accuracy: 0.72, f1_score: 0.0\n",
      "Trained model for question 14, accuracy: 0.71, f1_score: 0.83\n",
      "Trained model for question 15, accuracy: 0.52, f1_score: 0.0\n",
      "Trained model for question 16, accuracy: 0.73, f1_score: 0.85\n",
      "Trained model for question 17, accuracy: 0.69, f1_score: 0.82\n",
      "Trained model for question 18, accuracy: 0.95, f1_score: 0.97\n",
      "Mean accuracy: 0.7327\n",
      "Mean f1_score: 0.7541\n"
     ]
    }
   ],
   "source": [
    "# labels = pd.read_csv(\"data/processed/labels.csv\")\n",
    "models = {}\n",
    "\n",
    "for q in labels['q'].unique():\n",
    "    # get X\n",
    "    X = data_all['5_12'].iloc[:, 2:].values\n",
    "    # get y\n",
    "    y = labels['correct'][labels['q'] == q].values\n",
    "    # Creating training and test split\n",
    "    _, _, _, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "    # get distribution of y\n",
    "    dist = np.unique(y_test, return_counts=True)[1]\n",
    "    prob_0 = dist[0] / (dist[0] + dist[1])\n",
    "    if prob_0 > 0.5:\n",
    "        y_pred = np.zeros(len(y_test))\n",
    "    else:\n",
    "        y_pred = np.ones(len(y_test))\n",
    "\n",
    "    # Get accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Trained model for question {q}, accuracy: {round(acc, 2)}, f1_score: {round(f1, 2)}\")\n",
    "    models[f\"Question_{q}\"] = {'model' : None, 'prob_0': prob_0, 'prob_1': prob_1, 'acc': acc, 'f1_score': f1}\n",
    "\n",
    "print(f\"Mean accuracy: {round(np.mean([models[q]['acc'] for q in models.keys()]), 4)}\")\n",
    "print(f\"Mean f1_score: {round(np.mean([models[q]['f1_score'] for q in models.keys()]), 4)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for question 1, accuracy: 0.73, f1_score: 0.84\n",
      "Trained model for question 2, accuracy: 0.98, f1_score: 0.99\n",
      "Trained model for question 3, accuracy: 0.93, f1_score: 0.97\n",
      "Trained model for question 4, accuracy: 0.8, f1_score: 0.89\n",
      "Trained model for question 5, accuracy: 0.55, f1_score: 0.71\n",
      "Trained model for question 6, accuracy: 0.78, f1_score: 0.87\n",
      "Trained model for question 7, accuracy: 0.74, f1_score: 0.85\n",
      "Trained model for question 8, accuracy: 0.62, f1_score: 0.76\n",
      "Trained model for question 9, accuracy: 0.74, f1_score: 0.85\n",
      "Trained model for question 10, accuracy: 0.51, f1_score: 0.67\n",
      "Trained model for question 11, accuracy: 0.64, f1_score: 0.78\n",
      "Trained model for question 12, accuracy: 0.86, f1_score: 0.93\n",
      "Trained model for question 13, accuracy: 0.72, f1_score: 0.0\n",
      "Trained model for question 14, accuracy: 0.71, f1_score: 0.83\n",
      "Trained model for question 15, accuracy: 0.52, f1_score: 0.0\n",
      "Trained model for question 16, accuracy: 0.73, f1_score: 0.85\n",
      "Trained model for question 17, accuracy: 0.69, f1_score: 0.82\n",
      "Trained model for question 18, accuracy: 0.95, f1_score: 0.97\n",
      "Mean accuracy: 0.7327\n",
      "Mean f1_score: 0.7541\n"
     ]
    }
   ],
   "source": [
    "# labels = pd.read_csv(\"data/processed/labels.csv\")\n",
    "models = {}\n",
    "\n",
    "for q in labels['q'].unique():\n",
    "    # get X\n",
    "    X = data_all['13_22'].iloc[:, 2:].values\n",
    "    # get y\n",
    "    y = labels['correct'][labels['q'] == q].values\n",
    "    # Creating training and test split\n",
    "    _, _, _, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "    # get distribution of y\n",
    "    dist = np.unique(y_test, return_counts=True)[1]\n",
    "    prob_0 = dist[0] / (dist[0] + dist[1])\n",
    "    if prob_0 > 0.5:\n",
    "        y_pred = np.zeros(len(y_test))\n",
    "    else:\n",
    "        y_pred = np.ones(len(y_test))\n",
    "\n",
    "    # Get accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Trained model for question {q}, accuracy: {round(acc, 2)}, f1_score: {round(f1, 2)}\")\n",
    "    models[f\"{q}\"] = {'model' : None, 'prob_0': prob_0, 'prob_1': prob_1, 'acc': acc, 'f1_score': f1}\n",
    "\n",
    "print(f\"Mean accuracy: {round(np.mean([models[q]['acc'] for q in models.keys()]), 4)}\")\n",
    "print(f\"Mean f1_score: {round(np.mean([models[q]['f1_score'] for q in models.keys()]), 4)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'1': {'model': None,\n  'prob_0': 0.2724572075258169,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.7275427924741831,\n  'f1_score': 0.8422862757943007},\n '2': {'model': None,\n  'prob_0': 0.02121940868581129,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.9787805913141887,\n  'f1_score': 0.9892765227337718},\n '3': {'model': None,\n  'prob_0': 0.06606309237515914,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.9339369076248408,\n  'f1_score': 0.9658400994806525},\n '4': {'model': None,\n  'prob_0': 0.20172584523977932,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.7982741547602207,\n  'f1_score': 0.8878225298930145},\n '5': {'model': None,\n  'prob_0': 0.4516904795586363,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.5483095204413637,\n  'f1_score': 0.7082686158063043},\n '6': {'model': None,\n  'prob_0': 0.2240769557221672,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.7759230442778328,\n  'f1_score': 0.8738250756730923},\n '7': {'model': None,\n  'prob_0': 0.2639694440514924,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.7360305559485075,\n  'f1_score': 0.8479465449804432},\n '8': {'model': None,\n  'prob_0': 0.38279813269203566,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.6172018673079643,\n  'f1_score': 0.763296011196641},\n '9': {'model': None,\n  'prob_0': 0.26368651860234826,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.7363134813976517,\n  'f1_score': 0.8481342675574385},\n '10': {'model': None,\n  'prob_0': 0.4945536851039751,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.5054463148960249,\n  'f1_score': 0.6714903213681639},\n '11': {'model': None,\n  'prob_0': 0.3563446031970576,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.6436553968029424,\n  'f1_score': 0.7831999311472587},\n '12': {'model': None,\n  'prob_0': 0.13707738011034093,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.8629226198896591,\n  'f1_score': 0.926418103120966},\n '13': {'model': None,\n  'prob_0': 0.7248550007073136,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.7248550007073136,\n  'f1_score': 0.0},\n '14': {'model': None,\n  'prob_0': 0.29240345169047954,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.7075965483095205,\n  'f1_score': 0.8287631513544859},\n '15': {'model': None,\n  'prob_0': 0.5190267364549441,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.5190267364549441,\n  'f1_score': 0.0},\n '16': {'model': None,\n  'prob_0': 0.26510114584806904,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.734898854151931,\n  'f1_score': 0.8471950424005219},\n '17': {'model': None,\n  'prob_0': 0.3122082331305701,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.6877917668694299,\n  'f1_score': 0.8150196965887184},\n '18': {'model': None,\n  'prob_0': 0.04937049087565427,\n  'prob_1': 0.7274849333672863,\n  'acc': 0.9506295091243457,\n  'f1_score': 0.9746899702661542}}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data.raw.jo_wilder.competition'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Reference\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# https://www.kaggle.com/code/philculliton/basic-submission-demo\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mraw\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m jo_wilder\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_preprocessing_steve\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pp_pipeline_noah\n\u001B[1;32m      7\u001B[0m env \u001B[38;5;241m=\u001B[39m jo_wilder\u001B[38;5;241m.\u001B[39mmake_env()\n",
      "File \u001B[0;32m~/Desktop/Drive/2. Areas/University/Master-TUC/M2/4_Forschungsmodul/student-performance/data/raw/jo_wilder/__init__.py:2\u001B[0m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompetition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m make_env\n\u001B[1;32m      4\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmake_env\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'data.raw.jo_wilder.competition'"
     ]
    }
   ],
   "source": [
    "# Reference\n",
    "# https://www.kaggle.com/code/philculliton/basic-submission-demo\n",
    "# https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n",
    "\n",
    "from data.raw import jo_wilder\n",
    "from utils.data_preprocessing_steve import pp_pipeline_noah\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "for (test, sample_submission) in iter_test:\n",
    "    test_df = pp_pipeline_noah(data=test, file_path=None, flatten=True, saveIntermediateFiles=False, dtypes=None, output=True)\n",
    "    grp = test_df.level_group.values[0]\n",
    "    a,b = limits[grp]\n",
    "    for t in range(a,b):\n",
    "        nbc = models[f\"Question_{t}\"]\n",
    "        if nbc['prob_0'] > 0.5:\n",
    "            predictions = np.zeros(len(test_df))\n",
    "            best_threshold = nbc['prob_0']\n",
    "        else:\n",
    "            predictions = np.ones(len(test_df))\n",
    "            best_threshold = nbc['prob_1']\n",
    "        mask = sample_submission.session_id.str.contains(f'q{t}')\n",
    "        n_predictions = (predictions > best_threshold).astype(int)\n",
    "        sample_submission.loc[mask,'correct'] = n_predictions.flatten()\n",
    "\n",
    "    env.predict(sample_submission)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}